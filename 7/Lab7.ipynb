{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 1\n",
    "Создайте Series из каждого из элементов: списка, ndarray и словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series из списка:\n",
      "0     a\n",
      "1     b\n",
      "2     c\n",
      "3     e\n",
      "4     d\n",
      "5     f\n",
      "6     g\n",
      "7     h\n",
      "8     i\n",
      "9     j\n",
      "10    k\n",
      "11    l\n",
      "12    m\n",
      "13    n\n",
      "14    o\n",
      "15    p\n",
      "16    q\n",
      "17    r\n",
      "18    s\n",
      "19    t\n",
      "20    u\n",
      "21    v\n",
      "22    w\n",
      "23    x\n",
      "24    y\n",
      "25    z\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "\n",
    "series_from_list = pd.Series(mylist)\n",
    "print(\"Series из списка:\")\n",
    "print(series_from_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Series из ndarray:\n",
      "0      0\n",
      "1      1\n",
      "2      2\n",
      "3      3\n",
      "4      4\n",
      "5      5\n",
      "6      6\n",
      "7      7\n",
      "8      8\n",
      "9      9\n",
      "10    10\n",
      "11    11\n",
      "12    12\n",
      "13    13\n",
      "14    14\n",
      "15    15\n",
      "16    16\n",
      "17    17\n",
      "18    18\n",
      "19    19\n",
      "20    20\n",
      "21    21\n",
      "22    22\n",
      "23    23\n",
      "24    24\n",
      "25    25\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "series_from_ndarray = pd.Series(myarr)\n",
    "print(\"\\nSeries из ndarray:\")\n",
    "print(series_from_ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Series из словаря:\n",
      "a     0\n",
      "b     1\n",
      "c     2\n",
      "e     3\n",
      "d     4\n",
      "f     5\n",
      "g     6\n",
      "h     7\n",
      "i     8\n",
      "j     9\n",
      "k    10\n",
      "l    11\n",
      "m    12\n",
      "n    13\n",
      "o    14\n",
      "p    15\n",
      "q    16\n",
      "r    17\n",
      "s    18\n",
      "t    19\n",
      "u    20\n",
      "v    21\n",
      "w    22\n",
      "x    23\n",
      "y    24\n",
      "z    25\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "series_from_dict = pd.Series(mydict)\n",
    "print(\"\\nSeries из словаря:\")\n",
    "print(series_from_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 2\n",
    "Преобразуйте `ser` в датафрейм с его индексом в качестве еще одного столбца датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  value\n",
      "0      a      0\n",
      "1      b      1\n",
      "2      c      2\n",
      "3      e      3\n",
      "4      d      4\n",
      "5      f      5\n",
      "6      g      6\n",
      "7      h      7\n",
      "8      i      8\n",
      "9      j      9\n",
      "10     k     10\n",
      "11     l     11\n",
      "12     m     12\n",
      "13     n     13\n",
      "14     o     14\n",
      "15     p     15\n",
      "16     q     16\n",
      "17     r     17\n",
      "18     s     18\n",
      "19     t     19\n",
      "20     u     20\n",
      "21     v     21\n",
      "22     w     22\n",
      "23     x     23\n",
      "24     y     24\n",
      "25     z     25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "ser = pd.Series(mydict)\n",
    "\n",
    "df = ser.reset_index()\n",
    "df.columns = ['index', 'value']\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 3\n",
    "Объедините `ser1` и `ser2`, чтобы сформировать датафрейм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "0     a     0\n",
      "1     b     1\n",
      "2     c     2\n",
      "3     e     3\n",
      "4     d     4\n",
      "5     f     5\n",
      "6     g     6\n",
      "7     h     7\n",
      "8     i     8\n",
      "9     j     9\n",
      "10    k    10\n",
      "11    l    11\n",
      "12    m    12\n",
      "13    n    13\n",
      "14    o    14\n",
      "15    p    15\n",
      "16    q    16\n",
      "17    r    17\n",
      "18    s    18\n",
      "19    t    19\n",
      "20    u    20\n",
      "21    v    21\n",
      "22    w    22\n",
      "23    x    23\n",
      "24    y    24\n",
      "25    z    25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "\n",
    "ser1 = pd.Series(mylist)\n",
    "ser2 = pd.Series(myarr)\n",
    "\n",
    "df = pd.DataFrame({'col1': ser1, 'col2': ser2})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 4\n",
    "Добавьте имя ряда  `ser`, назвав его `latin_letters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   latin_letters\n",
      "0              a\n",
      "1              b\n",
      "2              c\n",
      "3              e\n",
      "4              d\n",
      "5              f\n",
      "6              g\n",
      "7              h\n",
      "8              i\n",
      "9              j\n",
      "10             k\n",
      "11             l\n",
      "12             m\n",
      "13             n\n",
      "14             o\n",
      "15             p\n",
      "16             q\n",
      "17             r\n",
      "18             s\n",
      "19             t\n",
      "20             u\n",
      "21             v\n",
      "22             w\n",
      "23             x\n",
      "24             y\n",
      "25             z\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser.name = 'latin_letters'\n",
    "df = pd.DataFrame({ser.name: ser})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 5\n",
    "Из `ser1` удалите элементы, присутствующие в `ser2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "indices_to_remove = ser1[ser1.isin(ser2)].index\n",
    "ser1_filtered = ser1.drop(indices_to_remove)\n",
    "\n",
    "print(ser1_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 6\n",
    "Получить все элементы `ser1` и `ser2`, которые не являются общими для обоих рядов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "2    6\n",
      "3    7\n",
      "4    8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "ser1_not_in_ser2 = ser1[~ser1.isin(ser2)]\n",
    "ser2_not_in_ser1 = ser2[~ser2.isin(ser1)]\n",
    "result = pd.concat([ser1_not_in_ser2, ser2_not_in_ser1])\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 7\n",
    "Вычислите минимальное значение, 25-й процентиль, медиану, 75-й процентиль и максимальное значение `ser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимальное значение: 4.140272639153048\n",
      "25-й процентиль: 9.215013033551688\n",
      "Медиана (50-й процентиль): 10.721691218199643\n",
      "75-й процентиль: 12.986227753406158\n",
      "Максимальное значение: 20.035046369590603\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ser = pd.Series(np.random.normal(10, 5, 25))\n",
    "\n",
    "statistics = ser.describe(percentiles=[.25, .5, .75])\n",
    "\n",
    "print(\"Минимальное значение:\", statistics['min'])\n",
    "print(\"25-й процентиль:\", statistics['25%'])\n",
    "print(\"Медиана (50-й процентиль):\", statistics['50%'])\n",
    "print(\"75-й процентиль:\", statistics['75%'])\n",
    "print(\"Максимальное значение:\", statistics['max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 8\n",
    "Вычислите частоту встречаемости каждого уникального значения `ser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Частота встречаемости уникальных значений:\n",
      "a    7\n",
      "f    5\n",
      "h    3\n",
      "g    3\n",
      "e    3\n",
      "c    3\n",
      "d    3\n",
      "b    3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n",
    "\n",
    "value_counts = ser.value_counts()\n",
    "\n",
    "print(\"Частота встречаемости уникальных значений:\")\n",
    "print(value_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 9\n",
    "Из `ser` оставить 2 наиболее часто встречающихся элемента без изменений, а все остальные заменить на `Прочее`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2\n",
      "1     1\n",
      "2     2\n",
      "3     2\n",
      "4     1\n",
      "5     3\n",
      "6     3\n",
      "7     4\n",
      "8     1\n",
      "9     4\n",
      "10    1\n",
      "11    4\n",
      "dtype: int32\n",
      "0          2\n",
      "1          1\n",
      "2          2\n",
      "3          2\n",
      "4          1\n",
      "5     Прочее\n",
      "6     Прочее\n",
      "7     Прочее\n",
      "8          1\n",
      "9     Прочее\n",
      "10         1\n",
      "11    Прочее\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_6272\\3080988544.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Прочее' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  ser[~ser.isin(top_two_elements)] = 'Прочее'\n"
     ]
    }
   ],
   "source": [
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "print(ser)\n",
    "\n",
    "value_counts = ser.value_counts()\n",
    "top_two_elements = value_counts.index[:2]\n",
    "ser[~ser.isin(top_two_elements)] = 'Прочее'\n",
    "\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 10\n",
    "Разбейте ряд `ser` на 10 равных децилей и замените значения на название дециля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      7th\n",
      "1      5th\n",
      "2      8th\n",
      "3      8th\n",
      "4      7th\n",
      "5      6th\n",
      "6      2th\n",
      "7      1th\n",
      "8      3th\n",
      "9      9th\n",
      "10    10th\n",
      "11     9th\n",
      "12     4th\n",
      "13     5th\n",
      "14     3th\n",
      "15     4th\n",
      "16     6th\n",
      "17     1th\n",
      "18    10th\n",
      "19     2th\n",
      "dtype: category\n",
      "Categories (10, object): ['1th' < '2th' < '3th' < '4th' ... '7th' < '8th' < '9th' < '10th']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ser = pd.Series(np.random.random(20))\n",
    "deciles = pd.qcut(ser, q=10, labels=[f'{i}th' for i in range(1, 11)])\n",
    "\n",
    "print(deciles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 11\n",
    "Переформируйте ряд `ser` в датафрейм с 7 строками и 5 столбцами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4\n",
      "0  4  9  1  9  4\n",
      "1  5  5  1  1  1\n",
      "2  7  1  7  8  7\n",
      "3  5  7  4  6  3\n",
      "4  8  4  5  7  6\n",
      "5  9  9  1  4  7\n",
      "6  7  3  2  9  1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "df = pd.DataFrame(ser.values.reshape(7, 5))\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 12\n",
    "Найти позиции чисел, кратных 3, из ряда `ser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6\n",
      "1    5\n",
      "2    3\n",
      "3    6\n",
      "4    7\n",
      "5    5\n",
      "6    9\n",
      "dtype: int32\n",
      "Позиции чисел, кратных 3: Index([0, 2, 3, 6], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ser = pd.Series(np.random.randint(1, 10, 7))\n",
    "print(ser)\n",
    "positions = ser.index[ser % 3 == 0]\n",
    "\n",
    "print(\"Позиции чисел, кратных 3:\", positions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 13\n",
    "Из `ser` извлечь элементы, находящиеся на позициях в списке `pos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     a\n",
      "4     e\n",
      "8     i\n",
      "14    o\n",
      "20    u\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "\n",
    "pos = [0, 4, 8, 14, 20]\n",
    "result = ser[pos]\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 14\n",
    "Объедините `ser1` и `ser2` по вертикали и горизонтали (чтобы сформировать датафрейм)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объединение по вертикали:\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    d\n",
      "4    e\n",
      "dtype: object\n",
      "\n",
      "Объединение по горизонтали:\n",
      "   0  1\n",
      "0  0  a\n",
      "1  1  b\n",
      "2  2  c\n",
      "3  3  d\n",
      "4  4  e\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))\n",
    "\n",
    "vertical_concatenation = pd.concat([ser1, ser2], axis=0)\n",
    "horizontal_concatenation = pd.concat([ser1, ser2], axis=1)\n",
    "\n",
    "print(\"Объединение по вертикали:\")\n",
    "print(vertical_concatenation)\n",
    "\n",
    "print(\"\\nОбъединение по горизонтали:\")\n",
    "print(horizontal_concatenation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 15\n",
    "Получите позиции элементов `ser2` в `ser1` в виде списка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Позиции элементов ser2 в ser1: [5, 4, 0, 8]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])\n",
    "\n",
    "positions = [ser1[ser1 == val].index[0] for val in ser2]\n",
    "print(\"Позиции элементов ser2 в ser1:\", positions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 16\n",
    "Вычислить среднеквадратическую ошибку рядов `truth` и `pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mh:\\Другие компьютеры\\Ноутбук\\2023\\university\\DPO\\projJup\\AE\\LabXAE.ipynb Ячейка 34\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/%D0%94%D1%80%D1%83%D0%B3%D0%B8%D0%B5%20%D0%BA%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D1%8B/%D0%9D%D0%BE%D1%83%D1%82%D0%B1%D1%83%D0%BA/2023/university/DPO/projJup/AE/LabXAE.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/%D0%94%D1%80%D1%83%D0%B3%D0%B8%D0%B5%20%D0%BA%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D1%8B/%D0%9D%D0%BE%D1%83%D1%82%D0%B1%D1%83%D0%BA/2023/university/DPO/projJup/AE/LabXAE.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/%D0%94%D1%80%D1%83%D0%B3%D0%B8%D0%B5%20%D0%BA%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D1%8B/%D0%9D%D0%BE%D1%83%D1%82%D0%B1%D1%83%D0%BA/2023/university/DPO/projJup/AE/LabXAE.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/%D0%94%D1%80%D1%83%D0%B3%D0%B8%D0%B5%20%D0%BA%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D1%8B/%D0%9D%D0%BE%D1%83%D1%82%D0%B1%D1%83%D0%BA/2023/university/DPO/projJup/AE/LabXAE.ipynb#X45sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m truth \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(\u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/%D0%94%D1%80%D1%83%D0%B3%D0%B8%D0%B5%20%D0%BA%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D1%8B/%D0%9D%D0%BE%D1%83%D1%82%D0%B1%D1%83%D0%BA/2023/university/DPO/projJup/AE/LabXAE.ipynb#X45sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pred \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(\u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m)) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandom(\u001b[39m10\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\TimCheers\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\__init__.py:83\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[39m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[39m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[39m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     80\u001b[0m         __check_build,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         _distributor_init,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     )\n\u001b[1;32m---> 83\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone\n\u001b[0;32m     84\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_show_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n\u001b[0;32m     86\u001b[0m     __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     87\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcalibration\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mshow_versions\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    130\u001b[0m     ]\n",
      "File \u001b[1;32md:\\Users\\TimCheers\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_estimator_html_repr\u001b[39;00m \u001b[39mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_metadata_requests\u001b[39;00m \u001b[39mimport\u001b[39;00m _MetadataRequester\n",
      "File \u001b[1;32md:\\Users\\TimCheers\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\__init__.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mitertools\u001b[39;00m \u001b[39mimport\u001b[39;00m compress, islice\n\u001b[0;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m issparse\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m DataConversionWarning\n",
      "File \u001b[1;32md:\\Users\\TimCheers\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\__init__.py:287\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_matrix_io\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    286\u001b[0m \u001b[39m# For backward compatibility with v0.19.\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m csgraph\n\u001b[0;32m    289\u001b[0m \u001b[39m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    291\u001b[0m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[0;32m    292\u001b[0m     lil, sparsetools, sputils\n\u001b[0;32m    293\u001b[0m )\n",
      "File \u001b[1;32md:\\Users\\TimCheers\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\csgraph\\__init__.py:185\u001b[0m\n\u001b[0;32m    157\u001b[0m __docformat__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrestructuredtext en\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mconnected_components\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    160\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mlaplacian\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    161\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mshortest_path\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mcsgraph_to_masked\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    183\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mNegativeCycleError\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m--> 185\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_laplacian\u001b[39;00m \u001b[39mimport\u001b[39;00m laplacian\n\u001b[0;32m    186\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_shortest_path\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    187\u001b[0m     shortest_path, floyd_warshall, dijkstra, bellman_ford, johnson,\n\u001b[0;32m    188\u001b[0m     NegativeCycleError\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    190\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_traversal\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    191\u001b[0m     breadth_first_order, depth_first_order, breadth_first_tree,\n\u001b[0;32m    192\u001b[0m     depth_first_tree, connected_components\n\u001b[0;32m    193\u001b[0m )\n",
      "File \u001b[1;32md:\\Users\\TimCheers\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\csgraph\\_laplacian.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m issparse\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearOperator\n\u001b[0;32m     10\u001b[0m \u001b[39m###############################################################################\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m# Graph laplacian\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlaplacian\u001b[39m(\n\u001b[0;32m     13\u001b[0m     csgraph,\n\u001b[0;32m     14\u001b[0m     normed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     symmetrized\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     22\u001b[0m ):\n",
      "File \u001b[1;32md:\\Users\\TimCheers\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\linalg\\__init__.py:120\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mSparse linear algebra (:mod:`scipy.sparse.linalg`)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m==================================================\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \n\u001b[0;32m    118\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_isolve\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    121\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dsolve\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_interface\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32md:\\Users\\TimCheers\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\linalg\\_isolve\\__init__.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39miterative\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mminres\u001b[39;00m \u001b[39mimport\u001b[39;00m minres\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlgmres\u001b[39;00m \u001b[39mimport\u001b[39;00m lgmres\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlsqr\u001b[39;00m \u001b[39mimport\u001b[39;00m lsqr\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlsmr\u001b[39;00m \u001b[39mimport\u001b[39;00m lsmr\n",
      "File \u001b[1;32md:\\Users\\TimCheers\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\linalg\\_isolve\\lgmres.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m \u001b[39mimport\u001b[39;00m LinAlgError\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m \u001b[39mimport\u001b[39;00m get_blas_funcs\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m make_system\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_gcrotmk\u001b[39;00m \u001b[39mimport\u001b[39;00m _fgmres\n",
      "File \u001b[1;32md:\\Users\\TimCheers\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\linalg\\__init__.py:218\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_decomp_schur\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    217\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_decomp_polar\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m--> 218\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_matfuncs\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    219\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mblas\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    220\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlapack\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32md:\\Users\\TimCheers\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\linalg\\_matfuncs.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_decomp_schur\u001b[39;00m \u001b[39mimport\u001b[39;00m schur, rsf2csf\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_expm_frechet\u001b[39;00m \u001b[39mimport\u001b[39;00m expm_frechet, expm_cond\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_matfuncs_sqrtm\u001b[39;00m \u001b[39mimport\u001b[39;00m sqrtm\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_matfuncs_expm\u001b[39;00m \u001b[39mimport\u001b[39;00m pick_pade_structure, pade_UV_calc\n\u001b[0;32m     21\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mexpm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcosm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msinm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtanm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcoshm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msinhm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtanhm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlogm\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mfunm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msignm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msqrtm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfractional_matrix_power\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mexpm_frechet\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     23\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mexpm_cond\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mkhatri_rao\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32md:\\Users\\TimCheers\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\linalg\\_matfuncs_sqrtm.py:24\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSqrtmError\u001b[39;00m(np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mLinAlgError):\n\u001b[0;32m     21\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_matfuncs_sqrtm_triu\u001b[39;00m \u001b[39mimport\u001b[39;00m within_block_loop  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sqrtm_triu\u001b[39m(T, blocksize\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m):\n\u001b[0;32m     28\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m    Matrix square root of an upper triangular matrix.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m \n\u001b[0;32m     52\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:405\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)\n",
    "print(truth)\n",
    "print(pred)\n",
    "mse = mean_squared_error(truth, pred)\n",
    "\n",
    "print(\"Среднеквадратическая ошибка (MSE):\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 17\n",
    "В каждом слове `ser` поставьте первый символ каждого слова в верхний регистр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     How\n",
      "1      To\n",
      "2    Kick\n",
      "3    Ass?\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "result = ser.str.title()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 18\n",
    "В каждом слове `ser` посчитайте число символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3\n",
      "1    2\n",
      "2    4\n",
      "3    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "character_count = ser.str.len()\n",
    "print(character_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 19\n",
    "\n",
    "Вычислите разность разностей между последовательно идущими числами в `ser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      NaN\n",
      "1      NaN\n",
      "2   1.0000\n",
      "3   1.0000\n",
      "4   1.0000\n",
      "5   1.0000\n",
      "6   0.0000\n",
      "7   2.0000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "result = ser.diff().diff()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 20\n",
    "\n",
    "Преобразуйте строковое представление дат в `datetime64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2010-01-01\n",
      "1          NaT\n",
      "2          NaT\n",
      "3          NaT\n",
      "4          NaT\n",
      "5          NaT\n",
      "dtype: datetime64[ns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_5576\\981038107.py:5: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  converted_dates = pd.to_datetime(ser, errors='coerce', infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "converted_dates = pd.to_datetime(ser, errors='coerce', infer_datetime_format=True)\n",
    "print(converted_dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 21\n",
    "\n",
    "Получите из `ser` день месяца, номер недели, день года и день недели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  [1.0, nan, nan, nan, nan, nan]\n",
      "Week number:  [53, <NA>, <NA>, <NA>, <NA>, <NA>]\n",
      "Day num of year:  [1.0, nan, nan, nan, nan, nan]\n",
      "Day of week:  ['Friday', nan, nan, nan, nan, nan]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Создаем серию\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "# Преобразуем строки в datetime64\n",
    "dates = pd.to_datetime(ser, errors='coerce')\n",
    "\n",
    "# Извлекаем нужные компоненты\n",
    "day_of_month = dates.dt.day\n",
    "week_number = dates.dt.isocalendar().week\n",
    "day_of_year = dates.dt.dayofyear\n",
    "day_of_week = dates.dt.day_name()\n",
    "\n",
    "# Выводим результаты\n",
    "print(\"Date: \", day_of_month.tolist())\n",
    "print(\"Week number: \", week_number.tolist())\n",
    "print(\"Day num of year: \", day_of_year.tolist())\n",
    "print(\"Day of week: \", day_of_week.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 22\n",
    "\n",
    "Замените элементы `ser` на даты, начинающиеся с 4-го числа соответствующего месяца."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2010-01-04\n",
      "1   2011-02-04\n",
      "2   2012-03-04\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Создаем серию\n",
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n",
    "\n",
    "# Преобразуем строки в datetime64, начиная с 4-го числа месяца\n",
    "converted_dates = pd.to_datetime(ser, format='%b %Y', errors='coerce') + pd.offsets.MonthBegin(0) + pd.DateOffset(days=3)\n",
    "\n",
    "# Выводим результаты\n",
    "print(converted_dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 23\n",
    "\n",
    "Из `ser` извлеките слова, содержащие не менее 2 гласных букв."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Apple\n",
      "1    Orange\n",
      "4     Money\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n",
    "def count_vowels(word):\n",
    "    vowels = set(\"AEIOUaeiou\")\n",
    "    return sum(1 for char in word if char in vowels)\n",
    "\n",
    "result = ser[ser.apply(count_vowels) >= 2]\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 24\n",
    "\n",
    "Извлеките корректные адреса электронной почты из ряда `emails`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    rameses@egypt.com\n",
      "2            matt@t.co\n",
      "3    narendra@modi.com\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Создаем серию\n",
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,4}'\n",
    "\n",
    "# Извлекаем корректные адреса электронной почты\n",
    "correct_emails = emails[emails.str.contains(pattern, na=False)]\n",
    "\n",
    "# Выводим результаты\n",
    "print(correct_emails)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 25\n",
    "\n",
    "Вычислить среднее значение веса в `weights` для каждого фрукта из `fruit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carrot', 'carrot', 'banana', 'carrot', 'apple', 'apple', 'apple', 'banana', 'banana', 'apple']\n",
      "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "fruit\n",
      "apple    7.0000\n",
      "banana   6.6667\n",
      "carrot   2.3333\n",
      "Name: weight, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "print(fruit.tolist())\n",
    "print(weights.tolist())\n",
    "\n",
    "df = pd.DataFrame({'fruit': fruit, 'weight': weights})\n",
    "average_weight = df.groupby('fruit')['weight'].mean()\n",
    "print(average_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 26\n",
    "\n",
    "Вычислить [евклидово расстояние](https://en.wikipedia.org/wiki/Euclidean_distance) между векторами $p$ и $q$, не используя встроенную формулу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.166\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Создаем векторы p и q\n",
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "\n",
    "# Вычисляем евклидово расстояние\n",
    "euclidean_distance = ((p - q) ** 2).sum() ** 0.5\n",
    "\n",
    "# Выводим результат\n",
    "print(round(euclidean_distance, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 27\n",
    "\n",
    "Получите позиции пиков (значений, окруженных с двух сторон меньшими значениями) в `ser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 7]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Создаем серию\n",
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n",
    "\n",
    "# Находим позиции пиков\n",
    "peaks, _ = find_peaks(ser)\n",
    "\n",
    "# Выводим результаты\n",
    "print(peaks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 28\n",
    "\n",
    "Замените пробелы в `my_str` на наименее часто встречающийся символ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbccdebcabedcgade\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Исходная строка\n",
    "my_str = 'dbc deb abed gade'\n",
    "\n",
    "# Подсчитываем частоту каждого символа, игнорируя пробелы\n",
    "counter = Counter(char for char in my_str if char != ' ')\n",
    "\n",
    "# Находим наименее часто встречающийся символ\n",
    "least_frequent_char = min(counter, key=counter.get)\n",
    "\n",
    "# Заменяем пробелы на наименее часто встречающийся символ\n",
    "result_str = ''.join(char if char != ' ' else least_frequent_char for char in my_str)\n",
    "\n",
    "# Выводим результат\n",
    "print(result_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 29\n",
    "\n",
    "Создайте временной ряд, начинающийся с `2000-01-01`, содержащий 10 субботних дней после этого и имеющий в качестве значений случайные числа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01    7\n",
      "2000-01-08    4\n",
      "2000-01-15    2\n",
      "2000-01-22    5\n",
      "2000-01-29    7\n",
      "2000-02-05    9\n",
      "2000-02-12    6\n",
      "2000-02-19    4\n",
      "2000-02-26    5\n",
      "2000-03-04    1\n",
      "Freq: W-SAT, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Устанавливаем начальную дату\n",
    "start_date = pd.to_datetime('2000-01-01')\n",
    "\n",
    "# Создаем временной ряд с 10 субботними днями\n",
    "date_index = pd.date_range(start_date, periods=10, freq='W-SAT')\n",
    "\n",
    "# Генерируем случайные значения\n",
    "random_values = np.random.randint(1, 10, size=10)\n",
    "\n",
    "# Создаем временной ряд\n",
    "time_series = pd.Series(random_values, index=date_index)\n",
    "\n",
    "# Выводим результат\n",
    "print(time_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 30\n",
    "\n",
    "В `ser` отсутствуют некоторые даты и значения. Сделайте так, чтобы все отсутствующие даты появились и заполнились значением из предыдущей даты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01    1.0000\n",
      "2000-01-02    1.0000\n",
      "2000-01-03   10.0000\n",
      "2000-01-04   10.0000\n",
      "2000-01-05   10.0000\n",
      "2000-01-06    3.0000\n",
      "2000-01-07    3.0000\n",
      "2000-01-08       NaN\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Создаем серию\n",
    "ser = pd.Series([1, 10, 3, np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "\n",
    "# Заполняем отсутствующие даты значениями из предыдущей даты\n",
    "filled_ser = ser.asfreq('D', method='pad')\n",
    "\n",
    "# Выводим результат\n",
    "print(filled_ser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 31\n",
    "\n",
    "Вычислите автокорреляции для первых 10 лагов `ser`. Определите, какой из лагов имеет наибольшую корреляцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2249699300317032, 0.013154629956023029, 0.7233830050416213, -0.14658728021737533, 0.09174835363329727, 0.5629621418723846, -0.33238209330279794, 0.3504040789428592, 0.29930491543971643, -0.7199444389858849]\n",
      "Lag having highest correlation: 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Создаем серию\n",
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
    "\n",
    "# Вычисляем автокорреляции для первых 10 лагов\n",
    "autocorrelations = [ser.autocorr(i) for i in range(1, 11)]\n",
    "\n",
    "# Выводим результаты\n",
    "print(autocorrelations)\n",
    "print(\"Lag having highest correlation:\", np.argmax(np.abs(autocorrelations)) + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 32\n",
    "\n",
    "Импортируйте каждую 50-ю строку набора данных [BostonHousing dataset](https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv) в виде датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       crim      zn   indus  chas    nox  ...  tax  ptratio        b   lstat  \\\n",
      "0    0.0063 18.0000  2.3100     0 0.5380  ...  296  15.3000 396.9000  4.9800   \n",
      "50   0.0887 21.0000  5.6400     0 0.4390  ...  243  16.8000 395.5600 13.4500   \n",
      "100  0.1487  0.0000  8.5600     0 0.5200  ...  384  20.9000 394.7600  9.4200   \n",
      "150  1.6566  0.0000 19.5800     0 0.8710  ...  403  14.7000 372.8000 14.1000   \n",
      "200  0.0178 95.0000  1.4700     0 0.4030  ...  402  17.0000 384.3000  4.4500   \n",
      "250  0.1403 22.0000  5.8600     0 0.4310  ...  330  19.1000 396.2800  5.9000   \n",
      "300  0.0442 70.0000  2.2400     0 0.4000  ...  358  14.8000 390.8600  6.0700   \n",
      "350  0.0621 40.0000  1.2500     0 0.4290  ...  335  19.7000 396.9000  5.9800   \n",
      "400 25.0461  0.0000 18.1000     0 0.6930  ...  666  20.2000 396.9000 26.7700   \n",
      "450  6.7177  0.0000 18.1000     0 0.7130  ...  666  20.2000   0.3200 17.4400   \n",
      "500  0.2244  0.0000  9.6900     0 0.5850  ...  391  19.2000 396.9000 14.3300   \n",
      "\n",
      "       medv  \n",
      "0   24.0000  \n",
      "50  19.7000  \n",
      "100 27.5000  \n",
      "150 21.5000  \n",
      "200 32.9000  \n",
      "250 24.4000  \n",
      "300 24.8000  \n",
      "350 22.9000  \n",
      "400  5.6000  \n",
      "450 13.4000  \n",
      "500 16.8000  \n",
      "\n",
      "[11 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL набора данных\n",
    "url = 'https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv'\n",
    "\n",
    "# Загрузка данных\n",
    "boston_data = pd.read_csv(url)\n",
    "\n",
    "# Импорт каждой 50-й строки в виде датафрейма\n",
    "every_50th_row = boston_data.iloc[::50, :]\n",
    "\n",
    "# Вывод результата\n",
    "print(every_50th_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 33\n",
    "\n",
    "Импортируйте набор данных [boston housing dataset](https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv), но при импорте измените столбец `'medv'` (*median house value*) так, чтобы значения < 25 стали `Low`, а > 25 - `High`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    crim      zn  indus  chas    nox  ...  tax  ptratio        b  lstat  medv\n",
      "0 0.0063 18.0000 2.3100     0 0.5380  ...  296  15.3000 396.9000 4.9800   Low\n",
      "1 0.0273  0.0000 7.0700     0 0.4690  ...  242  17.8000 396.9000 9.1400   Low\n",
      "2 0.0273  0.0000 7.0700     0 0.4690  ...  242  17.8000 392.8300 4.0300  High\n",
      "3 0.0324  0.0000 2.1800     0 0.4580  ...  222  18.7000 394.6300 2.9400  High\n",
      "4 0.0691  0.0000 2.1800     0 0.4580  ...  222  18.7000 396.9000 5.3300  High\n",
      "\n",
      "[5 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL набора данных\n",
    "url = 'https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv'\n",
    "\n",
    "# Загрузка данных\n",
    "boston_data = pd.read_csv(url)\n",
    "\n",
    "# Изменение значения столбца 'medv'\n",
    "boston_data['medv'] = boston_data['medv'].apply(lambda x: 'Low' if x < 25 else 'High')\n",
    "\n",
    "# Вывод результата\n",
    "print(boston_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 34\n",
    "\n",
    "Создайте датафрейм со строками в виде шагов (интервалов) заданного ряда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 1  2  3  4]\n",
      " [ 2  3  4  5]\n",
      " [ 3  4  5  6]\n",
      " [ 4  5  6  7]\n",
      " [ 5  6  7  8]\n",
      " [ 6  7  8  9]\n",
      " [ 7  8  9 10]\n",
      " [ 8  9 10 11]\n",
      " [ 9 10 11 12]\n",
      " [10 11 12 13]\n",
      " [11 12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Задаем ряд\n",
    "L = pd.Series(range(15))\n",
    "\n",
    "# Создаем датафрейм со строками в виде шагов\n",
    "step_size = 4\n",
    "df = pd.concat([L.shift(-i) for i in range(step_size)], axis=1).dropna().astype(int)\n",
    "\n",
    "# Выводим результат\n",
    "print(df.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 35\n",
    "\n",
    "Импортируйте столбцы 'crim' и 'medv' из набора данных [BostonHousing dataset](https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv) в виде датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    crim    medv\n",
      "0 0.0063 24.0000\n",
      "1 0.0273 21.6000\n",
      "2 0.0273 34.7000\n",
      "3 0.0324 33.4000\n",
      "4 0.0691 36.2000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL набора данных\n",
    "url = 'https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv'\n",
    "\n",
    "# Загрузка данных\n",
    "boston_data = pd.read_csv(url, usecols=['crim', 'medv'])\n",
    "\n",
    "# Вывод результата\n",
    "print(boston_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 36\n",
    "\n",
    "Получите количество строк, столбцов, тип данных и суммарную статистику каждого столбца набора данных [Cars93](https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv). Также получите эквивалент датафрейма в виде numpy-массива и списка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93 entries, 0 to 92\n",
      "Data columns (total 27 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Manufacturer        89 non-null     object \n",
      " 1   Model               92 non-null     object \n",
      " 2   Type                90 non-null     object \n",
      " 3   Min.Price           86 non-null     float64\n",
      " 4   Price               91 non-null     float64\n",
      " 5   Max.Price           88 non-null     float64\n",
      " 6   MPG.city            84 non-null     float64\n",
      " 7   MPG.highway         91 non-null     float64\n",
      " 8   AirBags             55 non-null     object \n",
      " 9   DriveTrain          86 non-null     object \n",
      " 10  Cylinders           88 non-null     object \n",
      " 11  EngineSize          91 non-null     float64\n",
      " 12  Horsepower          86 non-null     float64\n",
      " 13  RPM                 90 non-null     float64\n",
      " 14  Rev.per.mile        87 non-null     float64\n",
      " 15  Man.trans.avail     88 non-null     object \n",
      " 16  Fuel.tank.capacity  85 non-null     float64\n",
      " 17  Passengers          91 non-null     float64\n",
      " 18  Length              89 non-null     float64\n",
      " 19  Wheelbase           92 non-null     float64\n",
      " 20  Width               87 non-null     float64\n",
      " 21  Turn.circle         88 non-null     float64\n",
      " 22  Rear.seat.room      89 non-null     float64\n",
      " 23  Luggage.room        74 non-null     float64\n",
      " 24  Weight              86 non-null     float64\n",
      " 25  Origin              88 non-null     object \n",
      " 26  Make                90 non-null     object \n",
      "dtypes: float64(18), object(9)\n",
      "memory usage: 19.7+ KB\n",
      "Информация о датафрейме:\n",
      "None\n",
      "\n",
      "Эквивалент в виде numpy-массива:\n",
      "[['Acura' 'Integra' 'Small' ... 2705.0 'non-USA' 'Acura Integra']\n",
      " [nan 'Legend' 'Midsize' ... 3560.0 'non-USA' 'Acura Legend']\n",
      " ['Audi' '90' 'Compact' ... 3375.0 'non-USA' 'Audi 90']\n",
      " ...\n",
      " ['Volkswagen' 'Corrado' 'Sporty' ... 2810.0 'non-USA'\n",
      "  'Volkswagen Corrado']\n",
      " ['Volvo' '240' 'Compact' ... 2985.0 'non-USA' 'Volvo 240']\n",
      " [nan '850' 'Midsize' ... 3245.0 'non-USA' 'Volvo 850']]\n",
      "\n",
      "Эквивалент в виде списка:\n",
      "[['Acura', 'Integra', 'Small', 12.9, 15.9, 18.8, 25.0, 31.0, nan, 'Front', '4', 1.8, 140.0, 6300.0, 2890.0, 'Yes', 13.2, 5.0, 177.0, 102.0, 68.0, 37.0, 26.5, nan, 2705.0, 'non-USA', 'Acura Integra'], [nan, 'Legend', 'Midsize', 29.2, 33.9, 38.7, 18.0, 25.0, 'Driver & Passenger', 'Front', '6', 3.2, 200.0, 5500.0, 2335.0, 'Yes', 18.0, 5.0, 195.0, 115.0, 71.0, 38.0, 30.0, 15.0, 3560.0, 'non-USA', 'Acura Legend'], ['Audi', '90', 'Compact', 25.9, 29.1, 32.3, 20.0, 26.0, 'Driver only', 'Front', '6', 2.8, 172.0, 5500.0, 2280.0, 'Yes', 16.9, 5.0, 180.0, 102.0, 67.0, 37.0, 28.0, 14.0, 3375.0, 'non-USA', 'Audi 90'], ['Audi', '100', 'Midsize', nan, 37.7, 44.6, 19.0, 26.0, 'Driver & Passenger', nan, '6', nan, 172.0, 5500.0, 2535.0, nan, 21.1, 6.0, 193.0, 106.0, nan, 37.0, 31.0, 17.0, 3405.0, 'non-USA', 'Audi 100'], ['BMW', '535i', 'Midsize', nan, 30.0, nan, 22.0, 30.0, nan, 'Rear', '4', 3.5, 208.0, 5700.0, 2545.0, 'Yes', 21.1, 4.0, 186.0, 109.0, 69.0, 39.0, 27.0, 13.0, 3640.0, 'non-USA', 'BMW 535i'], ['Buick', 'Century', 'Midsize', 14.2, 15.7, 17.3, 22.0, 31.0, 'Driver only', nan, '4', 2.2, 110.0, 5200.0, 2565.0, 'No', 16.4, 6.0, 189.0, 105.0, 69.0, 41.0, 28.0, 16.0, nan, 'USA', 'Buick Century'], ['Buick', 'LeSabre', 'Large', 19.9, 20.8, nan, 19.0, 28.0, 'Driver only', 'Front', '6', 3.8, 170.0, 4800.0, nan, 'No', nan, 6.0, 200.0, 111.0, 74.0, 42.0, 30.5, 17.0, 3470.0, 'USA', 'Buick LeSabre'], ['Buick', 'Roadmaster', 'Large', 22.6, 23.7, 24.9, 16.0, 25.0, 'Driver only', 'Rear', '6', 5.7, 180.0, 4000.0, 1320.0, 'No', 23.0, 6.0, 216.0, 116.0, 78.0, 45.0, 30.5, 21.0, 4105.0, 'USA', 'Buick Roadmaster'], ['Buick', 'Riviera', 'Midsize', 26.3, 26.3, 26.3, 19.0, 27.0, 'Driver only', 'Front', '6', 3.8, 170.0, 4800.0, 1690.0, 'No', 18.8, 5.0, 198.0, 108.0, nan, 41.0, 26.5, 14.0, 3495.0, 'USA', 'Buick Riviera'], ['Cadillac', 'DeVille', 'Large', 33.0, 34.7, 36.3, 16.0, 25.0, 'Driver only', 'Front', '8', 4.9, 200.0, 4100.0, nan, 'No', 18.0, 6.0, 206.0, 114.0, 73.0, 43.0, 35.0, 18.0, 3620.0, 'USA', 'Cadillac DeVille'], ['Cadillac', 'Seville', 'Midsize', 37.5, 40.1, 42.7, 16.0, 25.0, 'Driver & Passenger', 'Front', '8', 4.6, 295.0, 6000.0, 1985.0, 'No', 20.0, 5.0, 204.0, 111.0, 74.0, 44.0, 31.0, nan, 3935.0, 'USA', 'Cadillac Seville'], ['Chevrolet', 'Cavalier', 'Compact', 8.5, 13.4, 18.3, 25.0, 36.0, nan, nan, '4', 2.2, nan, 5200.0, 2380.0, 'Yes', 15.2, 5.0, 182.0, 101.0, 66.0, 38.0, 25.0, 13.0, 2490.0, 'USA', 'Chevrolet Cavalier'], ['Chevrolet', 'Corsica', 'Compact', 11.4, 11.4, 11.4, 25.0, 34.0, 'Driver only', 'Front', nan, 2.2, 110.0, 5200.0, 2665.0, 'Yes', 15.6, 5.0, 184.0, 103.0, 68.0, 39.0, 26.0, nan, 2785.0, 'USA', 'Chevrolet Corsica'], ['Chevrolet', 'Camaro', 'Sporty', 13.4, 15.1, 16.8, 19.0, 28.0, 'Driver & Passenger', 'Rear', nan, 3.4, 160.0, 4600.0, 1805.0, 'Yes', nan, 4.0, 193.0, 101.0, 74.0, 43.0, 25.0, 13.0, 3240.0, 'USA', 'Chevrolet Camaro'], ['Chevrolet', 'Lumina', 'Midsize', 13.4, 15.9, 18.4, nan, 29.0, nan, 'Front', '4', 2.2, nan, 5200.0, 2595.0, 'No', 16.5, 6.0, nan, 108.0, 71.0, nan, 28.5, 16.0, 3195.0, 'USA', 'Chevrolet Lumina'], ['Chevrolet', 'Lumina_APV', 'Van', 14.7, 16.3, 18.0, 18.0, 23.0, nan, 'Front', '6', 3.8, 170.0, 4800.0, 1690.0, 'No', 20.0, 7.0, 178.0, 110.0, 74.0, 44.0, 30.5, nan, 3715.0, 'USA', 'Chevrolet Lumina_APV'], ['Chevrolet', 'Astro', 'Van', 14.7, 16.6, 18.6, 15.0, 20.0, nan, '4WD', '6', 4.3, nan, 4000.0, 1790.0, 'No', 27.0, 8.0, 194.0, 111.0, 78.0, 42.0, 33.5, nan, 4025.0, 'USA', 'Chevrolet Astro'], ['Chevrolet', 'Caprice', 'Large', 18.0, 18.8, 19.6, 17.0, 26.0, 'Driver only', 'Rear', '8', 5.0, 170.0, 4200.0, 1350.0, 'No', 23.0, 6.0, 214.0, 116.0, 77.0, 42.0, 29.5, 20.0, 3910.0, 'USA', 'Chevrolet Caprice'], ['Chevrolet', 'Corvette', 'Sporty', 34.6, 38.0, 41.5, 17.0, 25.0, 'Driver only', 'Rear', '8', 5.7, 300.0, 5000.0, 1450.0, 'Yes', 20.0, 2.0, 179.0, 96.0, 74.0, 43.0, nan, nan, 3380.0, nan, 'Chevrolet Corvette'], [nan, 'Concorde', 'Large', 18.4, 18.4, 18.4, 20.0, 28.0, 'Driver & Passenger', 'Front', '6', 3.3, 153.0, 5300.0, 1990.0, 'No', 18.0, 6.0, 203.0, 113.0, 74.0, nan, 31.0, 15.0, 3515.0, 'USA', 'Chrylser Concorde'], ['Chrysler', 'LeBaron', 'Compact', 14.5, 15.8, 17.1, 23.0, 28.0, 'Driver & Passenger', 'Front', '4', 3.0, 141.0, 5000.0, 2090.0, 'No', 16.0, 6.0, 183.0, 104.0, 68.0, 41.0, 30.5, 14.0, 3085.0, 'USA', 'Chrysler LeBaron'], ['Chrysler', 'Imperial', 'Large', 29.5, 29.5, 29.5, 20.0, 26.0, 'Driver only', 'Front', '6', 3.3, 147.0, 4800.0, 1785.0, 'No', 16.0, 6.0, 203.0, 110.0, 69.0, 44.0, 36.0, 17.0, 3570.0, 'USA', 'Chrysler Imperial'], ['Dodge', 'Colt', 'Small', 7.9, 9.2, 10.6, 29.0, 33.0, nan, 'Front', '4', 1.5, 92.0, 6000.0, 3285.0, 'Yes', nan, 5.0, 174.0, 98.0, 66.0, 32.0, nan, 11.0, 2270.0, 'USA', 'Dodge Colt'], ['Dodge', 'Shadow', 'Small', 8.4, 11.3, 14.2, 23.0, 29.0, 'Driver only', 'Front', '4', 2.2, 93.0, 4800.0, nan, 'Yes', 14.0, 5.0, 172.0, 97.0, 67.0, 38.0, 26.5, nan, 2670.0, 'USA', 'Dodge Shadow'], ['Dodge', 'Spirit', 'Compact', 11.9, 13.3, 14.7, 22.0, 27.0, 'Driver only', 'Front', '4', 2.5, 100.0, 4800.0, 2535.0, 'Yes', nan, 6.0, 181.0, 104.0, 68.0, 39.0, 30.5, nan, 2970.0, 'USA', 'Dodge Spirit'], ['Dodge', 'Caravan', 'Van', nan, 19.0, 24.4, 17.0, 21.0, 'Driver only', '4WD', '6', 3.0, 142.0, 5000.0, 1970.0, 'No', 20.0, 7.0, 175.0, 112.0, 72.0, 42.0, 26.5, nan, 3705.0, 'USA', 'Dodge Caravan'], ['Dodge', 'Dynasty', 'Midsize', 14.8, 15.6, 16.4, 21.0, nan, 'Driver only', 'Front', nan, 2.5, 100.0, 4800.0, 2465.0, 'No', 16.0, 6.0, 192.0, 105.0, 69.0, 42.0, 30.5, 16.0, 3080.0, 'USA', 'Dodge Dynasty'], ['Dodge', 'Stealth', 'Sporty', 18.5, 25.8, 33.1, nan, 24.0, 'Driver only', '4WD', '6', 3.0, 300.0, 6000.0, 2120.0, 'Yes', 19.8, 4.0, 180.0, 97.0, nan, 40.0, 20.0, 11.0, 3805.0, 'USA', 'Dodge Stealth'], ['Eagle', 'Summit', 'Small', 7.9, 12.2, 16.5, 29.0, 33.0, nan, 'Front', '4', 1.5, 92.0, 6000.0, 2505.0, 'Yes', 13.2, 5.0, 174.0, 98.0, 66.0, 36.0, 26.5, 11.0, 2295.0, 'USA', 'Eagle Summit'], ['Eagle', 'Vision', 'Large', nan, 19.3, 21.2, 20.0, 28.0, 'Driver & Passenger', 'Front', '6', 3.5, nan, 5800.0, 1980.0, 'No', 18.0, 6.0, 202.0, 113.0, 74.0, 40.0, 30.0, 15.0, 3490.0, 'USA', 'Eagle Vision'], ['Ford', 'Festiva', 'Small', 6.9, 7.4, 7.9, 31.0, 33.0, nan, 'Front', '4', 1.3, 63.0, 5000.0, 3150.0, 'Yes', 10.0, 4.0, 141.0, 90.0, 63.0, 33.0, 26.0, 12.0, 1845.0, 'USA', 'Ford Festiva'], ['Ford', 'Escort', 'Small', 8.4, 10.1, 11.9, 23.0, 30.0, nan, 'Front', '4', 1.8, 127.0, 6500.0, 2410.0, nan, 13.2, 5.0, 171.0, 98.0, 67.0, 36.0, 28.0, 12.0, 2530.0, 'USA', 'Ford Escort'], ['Ford', 'Tempo', 'Compact', 10.4, 11.3, 12.2, 22.0, 27.0, nan, 'Front', '4', 2.3, 96.0, 4200.0, 2805.0, 'Yes', 15.9, 5.0, 177.0, 100.0, 68.0, nan, 27.5, 13.0, nan, 'USA', nan], ['Ford', 'Mustang', 'Sporty', 10.8, 15.9, 21.0, 22.0, 29.0, 'Driver only', 'Rear', '4', 2.3, 105.0, 4600.0, 2285.0, 'Yes', 15.4, 4.0, 180.0, 101.0, 68.0, 40.0, 24.0, 12.0, nan, 'USA', 'Ford Mustang'], ['Ford', 'Probe', 'Sporty', 12.8, 14.0, 15.2, nan, 30.0, 'Driver only', 'Front', '4', 2.0, 115.0, 5500.0, 2340.0, 'Yes', 15.5, 4.0, 179.0, 103.0, 70.0, 38.0, 23.0, 18.0, 2710.0, 'USA', 'Ford Probe'], ['Ford', 'Aerostar', 'Van', 14.5, 19.9, 25.3, 15.0, 20.0, 'Driver only', '4WD', '6', 3.0, 145.0, 4800.0, 2080.0, 'Yes', 21.0, 7.0, 176.0, 119.0, 72.0, 45.0, 30.0, nan, 3735.0, 'USA', 'Ford Aerostar'], ['Ford', 'Taurus', 'Midsize', 15.6, 20.2, 24.8, 21.0, 30.0, 'Driver only', 'Front', '6', 3.0, nan, 4800.0, 1885.0, 'No', nan, 5.0, 192.0, 106.0, 71.0, 40.0, 27.5, 18.0, 3325.0, 'USA', 'Ford Taurus'], ['Ford', 'Crown_Victoria', 'Large', 20.1, 20.9, 21.7, 18.0, 26.0, 'Driver only', 'Rear', '8', 4.6, 190.0, 4200.0, nan, 'No', 20.0, 6.0, 212.0, 114.0, 78.0, 43.0, 30.0, 21.0, 3950.0, 'USA', 'Ford Crown_Victoria'], ['Geo', 'Metro', 'Small', 6.7, 8.4, 10.0, 46.0, 50.0, nan, 'Front', '3', 1.0, 55.0, 5700.0, 3755.0, nan, 10.6, 4.0, 151.0, 93.0, 63.0, 34.0, 27.5, 10.0, 1695.0, 'non-USA', 'Geo Metro'], ['Geo', 'Storm', 'Sporty', 11.5, 12.5, 13.5, 30.0, 36.0, 'Driver only', 'Front', '4', 1.6, 90.0, 5400.0, 3250.0, 'Yes', 12.4, 4.0, 164.0, 97.0, nan, 37.0, 24.5, 11.0, 2475.0, 'non-USA', 'Geo Storm'], ['Honda', 'Prelude', 'Sporty', 17.0, 19.8, 22.7, 24.0, 31.0, 'Driver & Passenger', 'Front', '4', 2.3, 160.0, 5800.0, 2855.0, 'Yes', nan, 4.0, 175.0, 100.0, 70.0, 39.0, 23.5, 8.0, 2865.0, 'non-USA', 'Honda Prelude'], ['Honda', 'Civic', 'Small', 8.4, 12.1, 15.8, 42.0, 46.0, 'Driver only', 'Front', '4', 1.5, nan, 5900.0, 2650.0, 'Yes', 11.9, 4.0, 173.0, nan, 67.0, 36.0, 28.0, 12.0, nan, 'non-USA', 'Honda Civic'], ['Honda', 'Accord', 'Compact', 13.8, 17.5, 21.2, 24.0, 31.0, 'Driver & Passenger', 'Front', '4', 2.2, 140.0, 5600.0, nan, 'Yes', 17.0, 4.0, 185.0, 107.0, 67.0, 41.0, 28.0, 14.0, 3040.0, 'non-USA', 'Honda Accord'], ['Hyundai', 'Excel', 'Small', 6.8, 8.0, 9.2, 29.0, 33.0, nan, 'Front', '4', 1.5, 81.0, 5500.0, 2710.0, 'Yes', 11.9, 5.0, 168.0, 94.0, 63.0, 35.0, 26.0, 11.0, 2345.0, 'non-USA', 'Hyundai Excel'], ['Hyundai', 'Elantra', 'Small', 9.0, 10.0, 11.0, nan, 29.0, nan, 'Front', '4', 1.8, 124.0, 6000.0, 2745.0, 'Yes', 13.7, 5.0, 172.0, 98.0, 66.0, 36.0, 28.0, 12.0, 2620.0, 'non-USA', 'Hyundai Elantra'], ['Hyundai', 'Scoupe', nan, 9.1, 10.0, 11.0, 26.0, 34.0, nan, 'Front', '4', 1.5, 92.0, 5550.0, 2540.0, 'Yes', 11.9, 4.0, 166.0, 94.0, 64.0, 34.0, 23.5, 9.0, 2285.0, 'non-USA', nan], ['Hyundai', 'Sonata', 'Midsize', 12.4, 13.9, 15.3, 20.0, 27.0, nan, 'Front', '4', 2.0, 128.0, 6000.0, 2335.0, 'Yes', 17.2, 5.0, 184.0, 104.0, 69.0, 41.0, 31.0, nan, 2885.0, nan, 'Hyundai Sonata'], ['Infiniti', 'Q45', 'Midsize', 45.4, 47.9, nan, 17.0, 22.0, nan, 'Rear', '8', 4.5, 278.0, 6000.0, 1955.0, 'No', 22.5, 5.0, 200.0, 113.0, 72.0, 42.0, 29.0, 15.0, 4000.0, 'non-USA', 'Infiniti Q45'], ['Lexus', 'ES300', 'Midsize', 27.5, 28.0, 28.4, 18.0, 24.0, 'Driver only', 'Front', '6', 3.0, 185.0, nan, 2325.0, 'Yes', 18.5, 5.0, 188.0, 103.0, 70.0, 40.0, 27.5, 14.0, 3510.0, 'non-USA', 'Lexus ES300'], [nan, 'SC300', 'Midsize', 34.7, 35.2, 35.6, 18.0, 23.0, 'Driver & Passenger', 'Rear', '6', 3.0, 225.0, 6000.0, 2510.0, 'Yes', nan, 4.0, 191.0, 106.0, 71.0, 39.0, 25.0, 9.0, 3515.0, 'non-USA', 'Lexus SC300'], ['Lincoln', 'Continental', 'Midsize', 33.3, 34.3, 35.3, 17.0, 26.0, 'Driver & Passenger', nan, '6', 3.8, 160.0, 4400.0, 1835.0, 'No', 18.4, 6.0, 205.0, 109.0, 73.0, 42.0, 30.0, 19.0, 3695.0, 'USA', 'Lincoln Continental'], ['Lincoln', 'Town_Car', 'Large', 34.4, 36.1, 37.8, 18.0, 26.0, 'Driver & Passenger', 'Rear', '8', 4.6, 210.0, 4600.0, 1840.0, 'No', 20.0, nan, 219.0, 117.0, 77.0, 45.0, 31.5, 22.0, 4055.0, 'USA', 'Lincoln Town_Car'], ['Mazda', '323', 'Small', 7.4, 8.3, 9.1, 29.0, 37.0, nan, 'Front', '4', 1.6, 82.0, 5000.0, 2370.0, 'Yes', 13.2, 4.0, 164.0, 97.0, 66.0, 34.0, 27.0, 16.0, 2325.0, 'non-USA', 'Mazda 323'], ['Mazda', 'Protege', 'Small', 10.9, 11.6, 12.3, 28.0, 36.0, nan, 'Front', '4', 1.8, 103.0, 5500.0, 2220.0, 'Yes', 14.5, 5.0, 172.0, 98.0, 66.0, 36.0, 26.5, 13.0, 2440.0, 'non-USA', 'Mazda Protege'], ['Mazda', '626', 'Compact', 14.3, 16.5, 18.7, 26.0, 34.0, 'Driver only', 'Front', '4', 2.5, 164.0, 5600.0, 2505.0, 'Yes', 15.5, 5.0, 184.0, 103.0, 69.0, 40.0, 29.5, 14.0, 2970.0, 'non-USA', 'Mazda 626'], ['Mazda', 'MPV', 'Van', 16.6, 19.1, 21.7, 18.0, 24.0, nan, '4WD', '6', 3.0, 155.0, 5000.0, 2240.0, 'No', 19.6, 7.0, 190.0, 110.0, 72.0, 39.0, 27.5, nan, 3735.0, 'non-USA', 'Mazda MPV'], ['Mazda', 'RX-7', 'Sporty', 32.5, 32.5, 32.5, 17.0, 25.0, 'Driver only', nan, 'rotary', 1.3, 255.0, 6500.0, 2325.0, 'Yes', 20.0, 2.0, 169.0, 96.0, 69.0, nan, nan, nan, nan, 'non-USA', 'Mazda RX-7'], ['Mercedes-Benz', '190E', 'Compact', 29.0, 31.9, 34.9, nan, 29.0, 'Driver only', 'Rear', '4', 2.3, 130.0, 5100.0, 2425.0, 'Yes', 14.5, 5.0, 175.0, 105.0, 67.0, 34.0, 26.0, 12.0, 2920.0, nan, 'Mercedes-Benz 190E'], ['Mercedes-Benz', '300E', 'Midsize', 43.8, 61.9, 80.0, 19.0, 25.0, 'Driver & Passenger', 'Rear', '6', 3.2, 217.0, 5500.0, 2220.0, 'No', 18.5, 5.0, nan, 110.0, 69.0, 37.0, nan, 15.0, 3525.0, 'non-USA', 'Mercedes-Benz 300E'], ['Mercury', nan, 'Sporty', 13.3, 14.1, 15.0, 23.0, 26.0, 'Driver only', 'Front', '4', 1.6, 100.0, 5750.0, 2475.0, 'Yes', 11.1, 4.0, 166.0, 95.0, 65.0, 36.0, 19.0, 6.0, 2450.0, 'USA', 'Mercury Capri'], ['Mercury', 'Cougar', 'Midsize', 14.9, 14.9, 14.9, 19.0, 26.0, nan, 'Rear', '6', 3.8, 140.0, 3800.0, 1730.0, 'No', 18.0, 5.0, 199.0, 113.0, 73.0, 38.0, 28.0, 15.0, 3610.0, 'USA', 'Mercury Cougar'], ['Mitsubishi', 'Mirage', 'Small', 7.7, 10.3, 12.9, 29.0, nan, nan, 'Front', '4', 1.5, 92.0, 6000.0, 2505.0, 'Yes', 13.2, 5.0, 172.0, 98.0, 67.0, 36.0, 26.0, 11.0, 2295.0, 'non-USA', 'Mitsubishi Mirage'], ['Mitsubishi', 'Diamante', 'Midsize', 22.4, 26.1, nan, 18.0, 24.0, 'Driver only', 'Front', '6', 3.0, 202.0, 6000.0, 2210.0, 'No', 19.0, 5.0, 190.0, 107.0, 70.0, 43.0, 27.5, 14.0, 3730.0, 'non-USA', 'Mitsubishi Diamante'], ['Nissan', 'Sentra', 'Small', 8.7, 11.8, 14.9, 29.0, 33.0, 'Driver only', 'Front', nan, 1.6, 110.0, 6000.0, 2435.0, 'Yes', 13.2, 5.0, 170.0, 96.0, 66.0, 33.0, 26.0, nan, nan, 'non-USA', 'Nissan Sentra'], ['Nissan', 'Altima', 'Compact', 13.0, 15.7, 18.3, 24.0, 30.0, 'Driver only', 'Front', '4', 2.4, 150.0, 5600.0, 2130.0, 'Yes', 15.9, 5.0, 181.0, 103.0, 67.0, 40.0, 28.5, 14.0, 3050.0, 'non-USA', 'Nissan Altima'], ['Nissan', 'Quest', 'Van', 16.7, 19.1, 21.5, 17.0, 23.0, nan, 'Front', '6', 3.0, nan, 4800.0, 2065.0, 'No', 20.0, 7.0, 190.0, 112.0, 74.0, 41.0, 27.0, nan, 4100.0, 'non-USA', 'Nissan Quest'], ['Nissan', 'Maxima', 'Midsize', 21.0, 21.5, 22.0, 21.0, 26.0, 'Driver only', 'Front', '6', 3.0, 160.0, 5200.0, 2045.0, nan, 18.5, 5.0, 188.0, 104.0, 69.0, 41.0, 28.5, 14.0, 3200.0, 'non-USA', 'Nissan Maxima'], ['Oldsmobile', 'Achieva', 'Compact', 13.0, 13.5, 14.0, 24.0, 31.0, nan, 'Front', '4', 2.3, 155.0, 6000.0, 2380.0, 'No', 15.2, 5.0, 188.0, 103.0, 67.0, 39.0, 28.0, 14.0, 2910.0, 'USA', 'Oldsmobile Achieva'], ['Oldsmobile', 'Cutlass_Ciera', 'Midsize', 14.2, 16.3, 18.4, 23.0, 31.0, 'Driver only', 'Front', '4', 2.2, 110.0, 5200.0, 2565.0, 'No', nan, 5.0, 190.0, 105.0, 70.0, 42.0, 28.0, 16.0, 2890.0, 'USA', 'Oldsmobile Cutlass_Ciera'], ['Oldsmobile', 'Silhouette', 'Van', 19.5, 19.5, 19.5, 18.0, 23.0, nan, 'Front', '6', 3.8, 170.0, 4800.0, 1690.0, 'No', 20.0, 7.0, nan, 110.0, 74.0, 44.0, 30.5, nan, 3715.0, 'USA', 'Oldsmobile Silhouette'], ['Oldsmobile', 'Eighty-Eight', 'Large', 19.5, 20.7, 21.9, nan, 28.0, 'Driver only', 'Front', '6', 3.8, 170.0, 4800.0, 1570.0, 'No', 18.0, 6.0, 201.0, 111.0, 74.0, 42.0, 31.5, 17.0, 3470.0, 'USA', 'Oldsmobile Eighty-Eight'], ['Plymouth', 'Laser', 'Sporty', 11.4, 14.4, 17.4, nan, 30.0, nan, '4WD', '4', 1.8, 92.0, 5000.0, 2360.0, 'Yes', 15.9, 4.0, 173.0, 97.0, 67.0, 39.0, 24.5, 8.0, 2640.0, nan, 'Plymouth Laser'], ['Pontiac', 'LeMans', 'Small', nan, 9.0, 9.9, 31.0, 41.0, nan, 'Front', '4', 1.6, 74.0, 5600.0, 3130.0, 'Yes', 13.2, 4.0, 177.0, 99.0, 66.0, 35.0, 25.5, 17.0, 2350.0, 'USA', 'Pontiac LeMans'], ['Pontiac', 'Sunbird', 'Compact', 9.4, 11.1, 12.8, nan, 31.0, nan, nan, '4', 2.0, 110.0, 5200.0, 2665.0, 'Yes', 15.2, 5.0, 181.0, 101.0, 66.0, 39.0, 25.0, 13.0, nan, 'USA', nan], ['Pontiac', 'Firebird', nan, 14.0, 17.7, 21.4, 19.0, 28.0, 'Driver & Passenger', 'Rear', '6', nan, 160.0, 4600.0, 1805.0, 'Yes', 15.5, 4.0, 196.0, 101.0, 75.0, 43.0, 25.0, 13.0, 3240.0, 'USA', 'Pontiac Firebird'], ['Pontiac', 'Grand_Prix', 'Midsize', 15.4, 18.5, 21.6, 19.0, 27.0, nan, 'Front', '6', 3.4, 200.0, 5000.0, 1890.0, 'Yes', 16.5, 5.0, 195.0, 108.0, 72.0, 41.0, 28.5, 16.0, 3450.0, 'USA', 'Pontiac Grand_Prix'], ['Pontiac', 'Bonneville', 'Large', 19.4, 24.4, 29.4, 19.0, 28.0, 'Driver & Passenger', 'Front', '6', 3.8, 170.0, 4800.0, 1565.0, 'No', 18.0, 6.0, 177.0, 111.0, 74.0, 43.0, 30.5, 18.0, 3495.0, 'USA', 'Pontiac Bonneville'], ['Saab', '900', 'Compact', 20.3, 28.7, 37.1, 20.0, 26.0, nan, 'Front', '4', 2.1, 140.0, 6000.0, 2910.0, 'Yes', 18.0, 5.0, nan, 99.0, 67.0, 37.0, 26.5, 14.0, 2775.0, 'non-USA', 'Saab 900'], ['Saturn', 'SL', 'Small', 9.2, nan, 12.9, nan, 38.0, 'Driver only', 'Front', '4', 1.9, 85.0, 5000.0, 2145.0, 'Yes', 12.8, 5.0, 176.0, 102.0, 68.0, 40.0, 26.5, nan, 2495.0, 'USA', 'Saturn SL'], ['Subaru', 'Justy', 'Small', 7.3, 8.4, 9.5, 33.0, 37.0, nan, '4WD', '3', 1.2, 73.0, 5600.0, 2875.0, 'Yes', 9.2, 4.0, 146.0, 90.0, 60.0, 32.0, 23.5, 10.0, 2045.0, 'non-USA', 'Subaru Justy'], ['Subaru', 'Loyale', 'Small', 10.5, 10.9, 11.3, 25.0, 30.0, nan, '4WD', '4', 1.8, 90.0, 5200.0, 3375.0, 'Yes', 15.9, 5.0, 175.0, 97.0, 65.0, 35.0, 27.5, 15.0, 2490.0, 'non-USA', 'Subaru Loyale'], ['Subaru', 'Legacy', 'Compact', 16.3, 19.5, 22.7, 23.0, 30.0, 'Driver only', '4WD', '4', 2.2, 130.0, nan, 2330.0, 'Yes', 15.9, 5.0, 179.0, 102.0, 67.0, 37.0, 27.0, 14.0, 3085.0, 'non-USA', 'Subaru Legacy'], ['Suzuki', 'Swift', nan, 7.3, 8.6, nan, 39.0, 43.0, nan, 'Front', '3', 1.3, 70.0, 6000.0, 3360.0, 'Yes', 10.6, 4.0, 161.0, 93.0, nan, 34.0, 27.5, 10.0, 1965.0, 'non-USA', 'Suzuki Swift'], ['Toyota', 'Tercel', 'Small', nan, 9.8, 11.8, 32.0, 37.0, 'Driver only', 'Front', '4', 1.5, 82.0, 5200.0, 3505.0, 'Yes', 11.9, nan, 162.0, 94.0, nan, 36.0, 24.0, 11.0, 2055.0, 'non-USA', 'Toyota Tercel'], ['Toyota', 'Celica', 'Sporty', 14.2, 18.4, 22.6, 25.0, 32.0, nan, 'Front', '4', 2.2, 135.0, nan, 2405.0, 'Yes', 15.9, 4.0, 174.0, 99.0, 69.0, nan, 23.0, 13.0, 2950.0, 'non-USA', 'Toyota Celica'], ['Toyota', 'Camry', 'Midsize', 15.2, nan, 21.2, 22.0, 29.0, 'Driver only', nan, '4', 2.2, 130.0, 5400.0, 2340.0, nan, 18.5, 5.0, 188.0, 103.0, 70.0, 38.0, 28.5, 15.0, 3030.0, 'non-USA', 'Toyota Camry'], ['Toyota', 'Previa', 'Van', nan, 22.7, 26.6, 18.0, 22.0, 'Driver only', '4WD', '4', 2.4, 138.0, 5000.0, 2515.0, 'Yes', 19.8, 7.0, 187.0, 113.0, 71.0, 41.0, 35.0, nan, 3785.0, 'non-USA', 'Toyota Previa'], ['Volkswagen', 'Fox', 'Small', 8.7, 9.1, 9.5, 25.0, 33.0, nan, 'Front', '4', 1.8, 81.0, 5500.0, 2550.0, 'Yes', 12.4, 4.0, 163.0, 93.0, 63.0, 34.0, 26.0, 10.0, 2240.0, 'non-USA', 'Volkswagen Fox'], ['Volkswagen', 'Eurovan', 'Van', 16.6, 19.7, 22.7, 17.0, 21.0, nan, 'Front', '5', 2.5, 109.0, 4500.0, 2915.0, 'Yes', 21.1, 7.0, 187.0, 115.0, 72.0, 38.0, 34.0, nan, 3960.0, nan, 'Volkswagen Eurovan'], ['Volkswagen', 'Passat', 'Compact', 17.6, 20.0, 22.4, 21.0, 30.0, nan, 'Front', '4', 2.0, 134.0, 5800.0, 2685.0, 'Yes', 18.5, 5.0, 180.0, 103.0, 67.0, 35.0, 31.5, 14.0, 2985.0, 'non-USA', 'Volkswagen Passat'], ['Volkswagen', 'Corrado', 'Sporty', 22.9, 23.3, 23.7, 18.0, 25.0, nan, 'Front', '6', 2.8, 178.0, 5800.0, 2385.0, 'Yes', 18.5, 4.0, 159.0, 97.0, 66.0, 36.0, 26.0, 15.0, 2810.0, 'non-USA', 'Volkswagen Corrado'], ['Volvo', '240', 'Compact', 21.8, 22.7, 23.5, 21.0, 28.0, 'Driver only', 'Rear', nan, 2.3, 114.0, 5400.0, 2215.0, 'Yes', 15.8, 5.0, 190.0, 104.0, 67.0, 37.0, 29.5, 14.0, 2985.0, 'non-USA', 'Volvo 240'], [nan, '850', 'Midsize', 24.8, 26.7, 28.5, 20.0, 28.0, 'Driver & Passenger', 'Front', '5', 2.4, 168.0, 6200.0, nan, 'Yes', 19.3, 5.0, 184.0, 105.0, 69.0, 38.0, 30.0, 15.0, 3245.0, 'non-USA', 'Volvo 850']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# URL набора данных\n",
    "url = 'https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv'\n",
    "\n",
    "# Загрузка данных\n",
    "cars_data = pd.read_csv(url)\n",
    "\n",
    "# Информация о датафрейме\n",
    "info_df = cars_data.info()\n",
    "\n",
    "# Эквивалент в виде numpy-массива\n",
    "numpy_array = cars_data.to_numpy()\n",
    "\n",
    "# Эквивалент в виде списка\n",
    "list_of_lists = cars_data.values.tolist()\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Информация о датафрейме:\")\n",
    "print(info_df)\n",
    "print(\"\\nЭквивалент в виде numpy-массива:\")\n",
    "print(numpy_array)\n",
    "print(\"\\nЭквивалент в виде списка:\")\n",
    "print(list_of_lists)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 37\n",
    "\n",
    "Извлеките номер строки и столбца конкретной ячейки по заданному критерию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Производитель, модель и тип с наибольшей ценой:\n",
      "Manufacturer    Mercedes-Benz\n",
      "Model                    300E\n",
      "Type                  Midsize\n",
      "Name: 58, dtype: object\n",
      "\n",
      "Максимальная цена: 61.9\n",
      "\n",
      "Номер строки и столбца ячейки с максимальной ценой:\n",
      "Номер строки: 58\n",
      "Номер столбца ('Price'): 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Находим индекс максимального значения в столбце 'Price'\n",
    "max_price_index = df['Price'].idxmax()\n",
    "\n",
    "# Получаем значение максимальной цены\n",
    "max_price = df.loc[max_price_index, 'Price']\n",
    "\n",
    "# Получаем номер строки и столбца ячейки с максимальным значением 'Price'\n",
    "row, col = df.index.get_loc(max_price_index), df.columns.get_loc('Price')\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Производитель, модель и тип с наибольшей ценой:\")\n",
    "print(df.loc[max_price_index, ['Manufacturer', 'Model', 'Type']])\n",
    "print(\"\\nМаксимальная цена:\", max_price)\n",
    "print(\"\\nНомер строки и столбца ячейки с максимальной ценой:\")\n",
    "print(\"Номер строки:\", row)\n",
    "print(\"Номер столбца ('Price'):\", col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 38\n",
    "\n",
    "Переименуйте в `df` столбец `Type` в `CarType` и замените `.` в именах столбцов на `_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n",
      "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
      "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
      "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
      "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
      "       'Make'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Переименование столбца 'Type' в 'CarType' и замена точек в именах столбцов\n",
    "df.rename(columns={'Type': 'CarType'}, inplace=True)\n",
    "df.columns = df.columns.str.replace('.', '_')\n",
    "\n",
    "# Вывод результатов\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 39\n",
    "\n",
    "Проверьте, нет ли в `df` отсутствующих значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наличие отсутствующих значений: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Проверка наличия отсутствующих значений\n",
    "missing_values = df.isna().any().any()\n",
    "\n",
    "# Вывод результата\n",
    "print(\"Наличие отсутствующих значений:\", missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 40\n",
    "\n",
    "Подсчитайте количество пропущенных значений в каждом столбце `df`. Какой столбец имеет наибольшее число пропущенных значений?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропущенных значений в каждом столбце:\n",
      "Manufacturer           4\n",
      "Model                  1\n",
      "Type                   3\n",
      "Min.Price              7\n",
      "Price                  2\n",
      "Max.Price              5\n",
      "MPG.city               9\n",
      "MPG.highway            2\n",
      "AirBags               38\n",
      "DriveTrain             7\n",
      "Cylinders              5\n",
      "EngineSize             2\n",
      "Horsepower             7\n",
      "RPM                    3\n",
      "Rev.per.mile           6\n",
      "Man.trans.avail        5\n",
      "Fuel.tank.capacity     8\n",
      "Passengers             2\n",
      "Length                 4\n",
      "Wheelbase              1\n",
      "Width                  6\n",
      "Turn.circle            5\n",
      "Rear.seat.room         4\n",
      "Luggage.room          19\n",
      "Weight                 7\n",
      "Origin                 5\n",
      "Make                   3\n",
      "dtype: int64\n",
      "\n",
      "Столбец с наибольшим числом пропущенных значений:\n",
      "Столбец: AirBags, Количество пропущенных: 38\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Подсчет количества пропущенных значений в каждом столбце\n",
    "missing_values_count = df.isna().sum()\n",
    "\n",
    "# Определение столбца с наибольшим числом пропущенных значений\n",
    "max_missing_column = missing_values_count.idxmax()\n",
    "max_missing_count = missing_values_count.max()\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Количество пропущенных значений в каждом столбце:\")\n",
    "print(missing_values_count)\n",
    "print(\"\\nСтолбец с наибольшим числом пропущенных значений:\")\n",
    "print(f\"Столбец: {max_missing_column}, Количество пропущенных: {max_missing_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 41\n",
    "\n",
    "Замените отсутствующие значения в столбцах `Min.Price` и `Max.Price` на соответствующие им средние значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные после замены отсутствующих значений:\n",
      "    Min.Price  Max.Price\n",
      "0     12.9000    18.8000\n",
      "1     29.2000    38.7000\n",
      "2     25.9000    32.3000\n",
      "3     17.1186    44.6000\n",
      "4     17.1186    21.4591\n",
      "..        ...        ...\n",
      "88    16.6000    22.7000\n",
      "89    17.6000    22.4000\n",
      "90    22.9000    23.7000\n",
      "91    21.8000    23.5000\n",
      "92    24.8000    28.5000\n",
      "\n",
      "[93 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Замена отсутствующих значений в столбце 'Min.Price' на среднее значение\n",
    "df['Min.Price'].fillna(df['Min.Price'].mean(), inplace=True)\n",
    "\n",
    "# Замена отсутствующих значений в столбце 'Max.Price' на среднее значение\n",
    "df['Max.Price'].fillna(df['Max.Price'].mean(), inplace=True)\n",
    "\n",
    "# Вывод результата\n",
    "print(\"Данные после замены отсутствующих значений:\")\n",
    "print(df[['Min.Price', 'Max.Price']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 42\n",
    "\n",
    "В `df` с помощью метода `apply` замените недостающие значения в `Min.Price` на среднее значение столбца, а в `Max.Price` — на медиану столбца."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные после замены отсутствующих значений:\n",
      "    Min.Price  Max.Price\n",
      "0     12.9000    18.8000\n",
      "1     29.2000    38.7000\n",
      "2     25.9000    32.3000\n",
      "3     17.1186    44.6000\n",
      "4     17.1186    19.1500\n",
      "..        ...        ...\n",
      "88    16.6000    22.7000\n",
      "89    17.6000    22.4000\n",
      "90    22.9000    23.7000\n",
      "91    21.8000    23.5000\n",
      "92    24.8000    28.5000\n",
      "\n",
      "[93 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Определение функции для замены отсутствующих значений на среднее значение\n",
    "def fillna_mean(column):\n",
    "    return column.fillna(column.mean())\n",
    "\n",
    "# Определение функции для замены отсутствующих значений на медиану\n",
    "def fillna_median(column):\n",
    "    return column.fillna(column.median())\n",
    "\n",
    "# Замена отсутствующих значений в столбце 'Min.Price' на среднее значение\n",
    "df['Min.Price'] = df[['Min.Price']].apply(fillna_mean, axis=0)\n",
    "\n",
    "# Замена отсутствующих значений в столбце 'Max.Price' на медиану\n",
    "df['Max.Price'] = df[['Max.Price']].apply(fillna_median, axis=0)\n",
    "\n",
    "# Вывод результата\n",
    "print(\"Данные после замены отсутствующих значений:\")\n",
    "print(df[['Min.Price', 'Max.Price']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 43\n",
    "\n",
    "Получите первый столбец (`a`) в `df` в виде датафрейма (а не в виде ряда)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первый столбец в виде датафрейма:\n",
      "    a\n",
      "0   0\n",
      "1   5\n",
      "2  10\n",
      "3  15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Создание исходного датафрейма\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "\n",
    "# Получение первого столбца в виде датафрейма\n",
    "first_column_df = df[['a']]\n",
    "\n",
    "# Вывод результата\n",
    "print(\"Первый столбец в виде датафрейма:\")\n",
    "print(first_column_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 44\n",
    "\n",
    "1. В `df` поменяйте местами столбцы `'a'` и `'c'`.\n",
    "2. Создайте обобщенную функцию для обмена данными между двумя столбцами без фиксированного задания имен столбцов.\n",
    "3. Отсортируйте столбцы в обратном алфавитном порядке, т.е. от столбца `'e'` до столбца `'a'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изначальный DataFrame: \n",
      "    a   b   c   d   e\n",
      "0   0   1   2   3   4\n",
      "1   5   6   7   8   9\n",
      "2  10  11  12  13  14\n",
      "3  15  16  17  18  19\n",
      "После обмена местами столбцов 'a' и 'c':\n",
      "    a   b   c   d   e\n",
      "0   2   1   0   3   4\n",
      "1   7   6   5   8   9\n",
      "2  12  11  10  13  14\n",
      "3  17  16  15  18  19\n",
      "\n",
      "После использования обобщенной функции для обмена столбцов 'a' и 'c':\n",
      "    a   b   c   d   e\n",
      "0   0   1   2   3   4\n",
      "1   5   6   7   8   9\n",
      "2  10  11  12  13  14\n",
      "3  15  16  17  18  19\n",
      "\n",
      "После сортировки столбцов в обратном алфавитном порядке:\n",
      "    e   d   c   b   a\n",
      "0   4   3   2   1   0\n",
      "1   9   8   7   6   5\n",
      "2  14  13  12  11  10\n",
      "3  19  18  17  16  15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Создание исходного датафрейма\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "print(\"Изначальный DataFrame: \")\n",
    "print(df)\n",
    "# 1. Поменять местами столбцы 'a' и 'c'\n",
    "df[['a', 'c']] = df[['c', 'a']]\n",
    "\n",
    "# Вывод результата после первого шага\n",
    "print(\"После обмена местами столбцов 'a' и 'c':\")\n",
    "print(df)\n",
    "\n",
    "# 2. Создать обобщенную функцию для обмена данными между двумя столбцами\n",
    "def swap_columns(df, col1, col2):\n",
    "    df[col1], df[col2] = df[col2].copy(), df[col1].copy()\n",
    "\n",
    "# Пример использования:\n",
    "swap_columns(df, 'a', 'c')\n",
    "print(\"\\nПосле использования обобщенной функции для обмена столбцов 'a' и 'c':\")\n",
    "print(df)\n",
    "\n",
    "# 3. Отсортировать столбцы в обратном алфавитном порядке\n",
    "df = df[sorted(df.columns, reverse=True)]\n",
    "print(\"\\nПосле сортировки столбцов в обратном алфавитном порядке:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 45\n",
    "\n",
    "Измените настройки отображения `pandas` при выводе на печать датафрейма `df`, чтобы он показывал максимум 10 строк и 10 столбцов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Manufacturer    Model     Type  Min.Price   Price  ...  Rear.seat.room  \\\n",
      "0         Acura  Integra    Small    12.9000 15.9000  ...         26.5000   \n",
      "1           NaN   Legend  Midsize    29.2000 33.9000  ...         30.0000   \n",
      "2          Audi       90  Compact    25.9000 29.1000  ...         28.0000   \n",
      "3          Audi      100  Midsize        NaN 37.7000  ...         31.0000   \n",
      "4           BMW     535i  Midsize        NaN 30.0000  ...         27.0000   \n",
      "..          ...      ...      ...        ...     ...  ...             ...   \n",
      "88   Volkswagen  Eurovan      Van    16.6000 19.7000  ...         34.0000   \n",
      "89   Volkswagen   Passat  Compact    17.6000 20.0000  ...         31.5000   \n",
      "90   Volkswagen  Corrado   Sporty    22.9000 23.3000  ...         26.0000   \n",
      "91        Volvo      240  Compact    21.8000 22.7000  ...         29.5000   \n",
      "92          NaN      850  Midsize    24.8000 26.7000  ...         30.0000   \n",
      "\n",
      "    Luggage.room    Weight   Origin                Make  \n",
      "0            NaN 2705.0000  non-USA       Acura Integra  \n",
      "1        15.0000 3560.0000  non-USA        Acura Legend  \n",
      "2        14.0000 3375.0000  non-USA             Audi 90  \n",
      "3        17.0000 3405.0000  non-USA            Audi 100  \n",
      "4        13.0000 3640.0000  non-USA            BMW 535i  \n",
      "..           ...       ...      ...                 ...  \n",
      "88           NaN 3960.0000      NaN  Volkswagen Eurovan  \n",
      "89       14.0000 2985.0000  non-USA   Volkswagen Passat  \n",
      "90       15.0000 2810.0000  non-USA  Volkswagen Corrado  \n",
      "91       14.0000 2985.0000  non-USA           Volvo 240  \n",
      "92       15.0000 3245.0000  non-USA           Volvo 850  \n",
      "\n",
      "[93 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Изменение настроек отображения\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "# Вывод датафрейма\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 46\n",
    "\n",
    "Исключите вывод научной нотации типа 'e-03' в `df` и выведите до 4 чисел после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   random\n",
      "0  0.0846\n",
      "1  0.6055\n",
      "2  0.2987\n",
      "3  0.0008\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Создание датафрейма\n",
    "df = pd.DataFrame(np.random.random(4)**10, columns=['random'])\n",
    "\n",
    "# Исключение научной нотации и вывод чисел с 4 знаками после запятой\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Вывод датафрейма\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 47\n",
    "\n",
    "Отформатируйте значения в столбце `'random'` из `df` в виде процентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   random\n",
      "0  0.1081\n",
      "1  0.2668\n",
      "2  0.4678\n",
      "3  0.1130\n",
      "   random\n",
      "0  10.81%\n",
      "1  26.68%\n",
      "2  46.78%\n",
      "3  11.30%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Создание датафрейма\n",
    "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
    "print(df)\n",
    "\n",
    "# Форматирование значения в проценты\n",
    "df['random'] = df['random'].apply(lambda x: '{:.2%}'.format(x))\n",
    "\n",
    "# Вывод датафрейма\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 48\n",
    "\n",
    "Из `df` отфильтруйте значения `Manufacturer`, `Model` и `Type` для каждой 20-й строки, начиная с 1-й (строка 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Manufacturer     Model     Type\n",
      "1           NaN    Legend  Midsize\n",
      "21     Chrysler  Imperial    Large\n",
      "41        Honda     Civic    Small\n",
      "61   Mitsubishi    Mirage    Small\n",
      "81       Subaru    Legacy  Compact\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Отфильтровывание значений\n",
    "filtered_values = df.loc[1::20, ['Manufacturer', 'Model', 'Type']]\n",
    "\n",
    "# Вывод результатов\n",
    "print(filtered_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 49\n",
    "\n",
    "В `df` замените `NaN` на `missing` в столбцах `Manufacturer`, `Model` и `Type` , создайте индекс как комбинацию этих трех столбцов и проверьте, является ли этот индекс первичным ключом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Min.Price  Max.Price\n",
      "Manufacturer Model   Type                         \n",
      "Acura        Integra Small      12.9000    18.8000\n",
      "missing      Legend  Midsize    29.2000    38.7000\n",
      "Audi         90      Compact    25.9000    32.3000\n",
      "             100     Midsize        NaN    44.6000\n",
      "BMW          535i    Midsize        NaN        NaN\n",
      "...                                 ...        ...\n",
      "Volkswagen   Eurovan Van        16.6000    22.7000\n",
      "             Passat  Compact    17.6000    22.4000\n",
      "             Corrado Sporty     22.9000    23.7000\n",
      "Volvo        240     Compact    21.8000    23.5000\n",
      "missing      850     Midsize    24.8000    28.5000\n",
      "\n",
      "[93 rows x 2 columns]\n",
      "\n",
      "Is the index a primary key? True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0, 1, 2, 3, 5])\n",
    "\n",
    "# Замена NaN на 'missing' в указанных столбцах\n",
    "df[['Manufacturer', 'Model', 'Type']] = df[['Manufacturer', 'Model', 'Type']].fillna('missing')\n",
    "\n",
    "# Создание индекса как комбинации столбцов 'Manufacturer', 'Model' и 'Type'\n",
    "df.set_index(['Manufacturer', 'Model', 'Type'], inplace=True)\n",
    "\n",
    "# Проверка, является ли индекс первичным ключом\n",
    "is_primary_key = df.index.is_unique\n",
    "\n",
    "# Вывод результатов\n",
    "print(df)\n",
    "print(\"\\nIs the index a primary key?\", is_primary_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 50\n",
    "\n",
    "Найти положение строки с 5-м наибольшим значением столбца `'a'` в `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c\n",
      "0  11  24  20\n",
      "1   7  19  17\n",
      "2  20  18  19\n",
      "3   1  12  13\n",
      "4  12  11  13\n",
      "5  17  20  23\n",
      "6   3  15   8\n",
      "7   7  23  17\n",
      "8   4  16   8\n",
      "9  21  25  11\n",
      "Индекс строки с 5-м наибольшим значением в столбце 'a': 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример DataFrame\n",
    "df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10, -1), columns=list('abc'))\n",
    "print(df)\n",
    "# Найти положение строки с 5-м наибольшим значением в столбце 'a'\n",
    "index_of_5th_largest = df['a'].nlargest(5).index[-1]\n",
    "\n",
    "# Вывести результат\n",
    "print(\"Индекс строки с 5-м наибольшим значением в столбце 'a':\", index_of_5th_largest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 51\n",
    "\n",
    "В `ser` найдите положение 2-го наибольшего значения, превышающего среднее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     84\n",
      "1     43\n",
      "2     71\n",
      "3     40\n",
      "4     35\n",
      "      ..\n",
      "10    77\n",
      "11     1\n",
      "12    49\n",
      "13    95\n",
      "14    44\n",
      "Length: 15, dtype: int32\n",
      "Положение 2-го наибольшего значения, превышающего среднее: 7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# pd.set_option('display.max_rows', 30)\n",
    "# Пример Series\n",
    "ser = pd.Series(np.random.randint(1, 100, 15))\n",
    "print(ser)\n",
    "# Найти положение 2-го наибольшего значения, превышающего среднее\n",
    "mean_value = ser.mean()\n",
    "filtered_values = ser[ser > mean_value].nlargest(2)\n",
    "position_of_2nd_largest_above_mean = filtered_values.index[-1]\n",
    "\n",
    "# Вывести результат\n",
    "print(\"Положение 2-го наибольшего значения, превышающего среднее:\", position_of_2nd_largest_above_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 52\n",
    "\n",
    "Получите две последние строки `df`, сумма строк которых больше 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1   2   3\n",
      "0   16  31  34  18\n",
      "1   16  19  30  33\n",
      "2   36  36  34  39\n",
      "3   37  11  31  15\n",
      "4   24  28  25  15\n",
      "..  ..  ..  ..  ..\n",
      "10  15  28  28  31\n",
      "11  28  37  14  36\n",
      "12  15  39  13  14\n",
      "13  21  23  16  16\n",
      "14  10  16  39  25\n",
      "\n",
      "[15 rows x 4 columns]\n",
      "     0   1   2   3\n",
      "10  15  28  28  31\n",
      "11  28  37  14  36\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример DataFrame\n",
    "df = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\n",
    "print(df)\n",
    "# Выбрать две последние строки сумма которых больше 100\n",
    "filtered_rows = df[df.sum(axis=1) > 100].tail(2)\n",
    "\n",
    "# Вывести результат\n",
    "print(filtered_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 53\n",
    "\n",
    "Замените все значения `ser`, находящиеся ниже 5%-ного и выше 95%-ного перцентиля, на соответствующие значения 5-го и 95-го перцентиля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.0160\n",
      "1     0.0160\n",
      "2     0.0189\n",
      "3     0.0259\n",
      "4     0.0356\n",
      "       ...  \n",
      "25   28.0722\n",
      "26   38.5662\n",
      "27   52.9832\n",
      "28   63.8767\n",
      "29   63.8767\n",
      "Length: 30, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример Series\n",
    "ser = pd.Series(np.logspace(-2, 2, 30))\n",
    "\n",
    "# Находим 5-й и 95-й перцентили\n",
    "percentile_5 = ser.quantile(0.05)\n",
    "percentile_95 = ser.quantile(0.95)\n",
    "\n",
    "# Заменяем значения вне диапазона на соответствующие перцентили\n",
    "ser = ser.apply(lambda x: x if percentile_5 <= x <= percentile_95 else (percentile_5 if x < percentile_5 else percentile_95))\n",
    "\n",
    "# Вывод результата\n",
    "print(ser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 54\n",
    "\n",
    "Перестройте `df` в максимально возможный квадрат с удалением отрицательных значений. При необходимости отбросьте наименьшие значения. Порядок положительных чисел в результате должен остаться тем же, что и в исходном варианте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0 -16  11  27   0   7  14 -12 -18  25   6\n",
      "1  17  23  45  33  43  30  -8  29 -12  14\n",
      "2  26  47  24  -7  47  19   9 -10  41   9\n",
      "3  14 -16  -8   3  20  29 -13  -8   4  32\n",
      "4  40  35  32 -18  34  16  25  18  13  45\n",
      "5  -6   6  20  43  49  25  22  46   2  37\n",
      "6   8  40   7   6  48  37  49   4  14  26\n",
      "7  -2  36  25  25   2  -3  44  40  47  -1\n",
      "8  19  24  34  11  30  44  19  34 -13  43\n",
      "9  26  48  10  45  -3  13  45  48  11   1\n",
      "        0       1       2       3       4       5       6       7       8  \\\n",
      "0 40.0000 48.0000 45.0000 45.0000 49.0000 44.0000 49.0000 48.0000 47.0000   \n",
      "1 26.0000 47.0000 34.0000 43.0000 48.0000 37.0000 45.0000 46.0000 41.0000   \n",
      "2 26.0000 40.0000 32.0000 33.0000 47.0000 30.0000 44.0000 40.0000 14.0000   \n",
      "3 19.0000 36.0000 25.0000 25.0000 43.0000 29.0000 25.0000 34.0000 13.0000   \n",
      "4 17.0000 35.0000 24.0000 11.0000 34.0000 25.0000 22.0000 29.0000 11.0000   \n",
      "5 14.0000 24.0000 20.0000  6.0000 30.0000 19.0000 19.0000 18.0000  4.0000   \n",
      "6  8.0000 23.0000 10.0000  3.0000 20.0000 16.0000  9.0000  4.0000  2.0000   \n",
      "7     NaN  6.0000  7.0000     NaN  2.0000 13.0000     NaN     NaN     NaN   \n",
      "\n",
      "        9  \n",
      "0 45.0000  \n",
      "1 43.0000  \n",
      "2 37.0000  \n",
      "3 32.0000  \n",
      "4 26.0000  \n",
      "5 14.0000  \n",
      "6  9.0000  \n",
      "7  1.0000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример DataFrame\n",
    "df = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10, -1))\n",
    "print(df)\n",
    "# Удаление отрицательных значений\n",
    "df[df < 0] = np.nan\n",
    "\n",
    "# Удаление строки с наименьшими значениями\n",
    "df = df.drop(df.sum(axis=1).idxmin())\n",
    "\n",
    "# Перестройка в квадрат\n",
    "df = df.apply(lambda x: x.sort_values(ascending=False).values)\n",
    "df = df.apply(lambda x: pd.Series(x.dropna().values))\n",
    "\n",
    "# Вывод результата\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 56\n",
    "\n",
    "Переверните строки датафрейма `df` (первая строка становится последней)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4\n",
      "0   0   1   2   3   4\n",
      "1   5   6   7   8   9\n",
      "2  10  11  12  13  14\n",
      "3  15  16  17  18  19\n",
      "4  20  21  22  23  24\n",
      "    0   1   2   3   4\n",
      "4  20  21  22  23  24\n",
      "3  15  16  17  18  19\n",
      "2  10  11  12  13  14\n",
      "1   5   6   7   8   9\n",
      "0   0   1   2   3   4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример DataFrame\n",
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "print(df)\n",
    "# Переворот строк\n",
    "df_flipped = df.iloc[::-1]\n",
    "\n",
    "# Вывод результата\n",
    "print(df_flipped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 57\n",
    "\n",
    "Получите бинарный код для столбца `'a'` в датафрейме `df` и добавьте его в виде столбцов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a_0    a_5   a_10   a_15   a_20   a   b   c   d   e\n",
      "0   True  False  False  False  False   0   1   2   3   4\n",
      "1  False   True  False  False  False   5   6   7   8   9\n",
      "2  False  False   True  False  False  10  11  12  13  14\n",
      "3  False  False  False   True  False  15  16  17  18  19\n",
      "4  False  False  False  False   True  20  21  22  23  24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример DataFrame\n",
    "df = pd.DataFrame(np.arange(25).reshape(5, -1), columns=list('abcde'))\n",
    "# Получение бинарного кода для столбца 'a'\n",
    "binary_code = pd.get_dummies(df['a'], prefix='a')\n",
    "\n",
    "# Добавление бинарного кода в виде столбцов в DataFrame\n",
    "df_with_binary = pd.concat([binary_code, df], axis=1)\n",
    "\n",
    "# Вывод результата\n",
    "print(df_with_binary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 58\n",
    "\n",
    "Получите название столбца с наибольшим количеством строчных максимумов в `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3\n",
      "0   6  84  84  72\n",
      "1  90  64  44  23\n",
      "2  71   2  21  22\n",
      "3  69  90  91  15\n",
      "4  54  44   6  89\n",
      "5  25  61  45  47\n",
      "6  10  55  16  23\n",
      "7  33  59  67  69\n",
      "8  34  36  63  79\n",
      "9  23  51  25  34\n",
      "Столбец с наибольшим количеством строчных максимумов: 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример DataFrame\n",
    "df = pd.DataFrame(np.random.randint(1, 100, 40).reshape(10, -1))\n",
    "print(df)\n",
    "# Функция для подсчета максимумов в каждом столбце\n",
    "def count_lowercase_max(column):\n",
    "    return column.apply(lambda x: sum(map(str.islower, str(x))))\n",
    "\n",
    "# Название столбца с наибольшим количеством строчных максимумов\n",
    "max_lowercase_col = df.apply(count_lowercase_max).idxmax()\n",
    "\n",
    "# Вывод результата\n",
    "print(\"Столбец с наибольшим количеством строчных максимумов:\", max_lowercase_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 59\n",
    "\n",
    "Создать новый столбец, в каждой строке которого будет указан номер строки, ближайшей по евклидову расстоянию к данной строке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 60\n",
    "\n",
    "Вычислите максимально возможное абсолютное значение корреляции каждого столбца с другими столбцами в `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    p   q   r   s   t   u   v   w   x   y\n",
      "a  73  76  50  28  95  66  86  29  35  42\n",
      "b  42  85  37  83  46  86  75  66  43  78\n",
      "c  30  91  57  60   4  34  58  13   1  42\n",
      "d  31  19   5  87  13  12  32  58  39  47\n",
      "e  54  11  30  67  34  19  47  24  99  85\n",
      "f  97   2  25  35  50  36   7  57  50  50\n",
      "g  37  30  27  28  42  55  95  24  29  36\n",
      "h  88  99  53  94  31  98  22  75  34  31\n",
      "{'p': 0.5203860401082717, 'q': 0.8225419174363632, 'r': 0.8225419174363632, 's': 0.5879721803306412, 't': 0.5770732086821655, 'u': 0.7296027953134212, 'v': 0.5351955372809225, 'w': 0.5879721803306414, 'x': 0.7320663604451946, 'y': 0.7320663604451947}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример DataFrame\n",
    "df = pd.DataFrame(np.random.randint(1, 100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh'))\n",
    "print(df)\n",
    "# Функция для вычисления максимально возможной абсолютной корреляции\n",
    "def max_possible_corr(column, df):\n",
    "    max_corr = 0\n",
    "    for other_column in df.columns:\n",
    "        if column != other_column:\n",
    "            corr = np.abs(df[column].corr(df[other_column]))\n",
    "            max_corr = max(max_corr, corr)\n",
    "    return max_corr\n",
    "\n",
    "# Вычисление максимально возможной абсолютной корреляции для каждого столбца\n",
    "max_corrs = {column: max_possible_corr(column, df) for column in df.columns}\n",
    "\n",
    "# Вывод результата\n",
    "print(max_corrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 61\n",
    "\n",
    "Вычислите минимум-максимум для каждой строки `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0  42   6  90  48  61  77  29  12  87  49\n",
      "1  56  26  40  20  76  19  14  23  51  33\n",
      "2  39  84  35  93  72  11  67   6  23  73\n",
      "3  85  13  84   1  44  27  28  68  15  25\n",
      "4  63  64  66  40  29  43   5  68  63  36\n",
      "5  98  44  40   1  11  59  22  75  15  58\n",
      "6  66  66  41  26  99  51   7  10  99  49\n",
      "7  25  47  76  54  63  84   4  34  54  78\n",
      "   Min  Max\n",
      "0    6   90\n",
      "1   14   76\n",
      "2    6   93\n",
      "3    1   85\n",
      "4    5   68\n",
      "5    1   98\n",
      "6    7   99\n",
      "7    4   84\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример DataFrame\n",
    "df = pd.DataFrame(np.random.randint(1, 100, 80).reshape(8, -1))\n",
    "print(df)\n",
    "# Функция для вычисления минимум-максимума\n",
    "def min_max(row):\n",
    "    return (row.min(), row.max())\n",
    "\n",
    "# Применение функции к каждой строке\n",
    "min_max_values = df.apply(min_max, axis=1)\n",
    "\n",
    "# Создание нового DataFrame с результатами\n",
    "result_df = pd.DataFrame(min_max_values.tolist(), columns=['Min', 'Max'])\n",
    "\n",
    "# Вывод результата\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 62\n",
    "\n",
    "Создайте новый столбец `penultimate`, который содержит второе по величине значение каждой строки `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4  ...   6   7   8   9  penultimate\n",
      "0  31  15  88  60  60  ...   2  34  68  10           68\n",
      "1  14  88  92  45  38  ...  18  58  82  24           91\n",
      "2   4  35  29  52  95  ...  72  78  15  25           78\n",
      "3  87  19  57  37   5  ...   3  36  94  78           88\n",
      "4  28  36  98  60  76  ...  49  69  80  96           96\n",
      "5  47  29   8  36   3  ...  72   6  73  25           72\n",
      "6  91  48  21  78  86  ...  69  19  51  50           86\n",
      "7  25  94   3  45  69  ...  28  52  68  51           69\n",
      "\n",
      "[8 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример DataFrame\n",
    "df = pd.DataFrame(np.random.randint(1, 100, 80).reshape(8, -1))\n",
    "\n",
    "# Функция для получения второго по величине значения\n",
    "def second_largest(row):\n",
    "    sorted_row = sorted(row, reverse=True)\n",
    "    return sorted_row[1] if len(sorted_row) > 1 else np.nan\n",
    "\n",
    "# Применение функции к каждой строке\n",
    "df['penultimate'] = df.apply(second_largest, axis=1)\n",
    "\n",
    "# Вывод результата\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 63\n",
    "\n",
    "1. Нормализуйте все столбцы `df`, вычитая среднее значение столбца и деля его на стандартное отклонение.\n",
    "2. Произведите ранжирование всех столбцов `df` таким образом, чтобы минимальное значение в каждом столбце было равно 0, а максимальное — 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нормализованный DataFrame:\n",
      "        0       1       2       3       4       5       6       7       8  \\\n",
      "0  0.0761  0.2152  0.1465  0.4552  1.9329 -0.6615 -0.0497  0.2601 -0.1086   \n",
      "1  0.4603 -1.8724  1.4563  1.3454 -0.2383  0.1060 -0.3558  0.2167  0.3257   \n",
      "2 -2.0695  0.1785 -0.9910  0.3743  0.6090 -0.8230 -1.0904  0.2167 -1.4903   \n",
      "3  1.0688  1.1308  0.5257 -0.5564 -0.2913 -0.9442 -0.1416  0.2167  0.5231   \n",
      "4  0.2042  0.0687 -1.4391 -1.5679 -0.9797  1.7218  1.3276  0.2167  0.0888   \n",
      "5 -0.7566 -0.9568  0.0086 -0.1517 -0.3442 -0.8230 -1.4883 -0.4334  1.8653   \n",
      "6  0.8446  0.1419  1.0082 -0.9610 -1.1915  1.1159  0.7155  1.4303 -0.3060   \n",
      "7  0.1721  1.0941 -0.7152  1.0621  0.5031  0.3080  1.0828 -2.1238 -0.8981   \n",
      "\n",
      "        9  \n",
      "0  0.3106  \n",
      "1  1.3140  \n",
      "2 -1.7918  \n",
      "3  0.6928  \n",
      "4 -0.3106  \n",
      "5  0.3584  \n",
      "6 -1.0273  \n",
      "7  0.4539  \n",
      "\n",
      "Ранжированный DataFrame:\n",
      "       0      1      2      3      4      5      6      7      8      9\n",
      "0 0.6837 0.6951 0.5476 0.6944 1.0000 0.1061 0.5109 0.6707 0.4118 0.6769\n",
      "1 0.8061 0.0000 1.0000 1.0000 0.3051 0.3939 0.4022 0.6585 0.5412 1.0000\n",
      "2 0.0000 0.6829 0.1548 0.6667 0.5763 0.0455 0.1413 0.6585 0.0000 0.0000\n",
      "3 1.0000 1.0000 0.6786 0.3472 0.2881 0.0000 0.4783 0.6585 0.6000 0.8000\n",
      "4 0.7245 0.6463 0.0000 0.0000 0.0678 1.0000 1.0000 0.6585 0.4706 0.4769\n",
      "5 0.4184 0.3049 0.5000 0.4861 0.2712 0.0455 0.0000 0.4756 1.0000 0.6923\n",
      "6 0.9286 0.6707 0.8452 0.2083 0.0000 0.7727 0.7826 1.0000 0.3529 0.2462\n",
      "7 0.7143 0.9878 0.2500 0.9028 0.5424 0.4697 0.9130 0.0000 0.1765 0.7231\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример DataFrame\n",
    "df = pd.DataFrame(np.random.randint(1, 100, 80).reshape(8, -1))\n",
    "\n",
    "# Нормализация: вычитание среднего и деление на стандартное отклонение\n",
    "normalized_df = (df - df.mean()) / df.std()\n",
    "\n",
    "# Вывод нормализованного DataFrame\n",
    "print(\"Нормализованный DataFrame:\")\n",
    "print(normalized_df)\n",
    "# Ранжирование: мин-макс шкала\n",
    "ranked_df = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "# Вывод ранжированного DataFrame\n",
    "print(\"\\nРанжированный DataFrame:\")\n",
    "print(ranked_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 64\n",
    "\n",
    "Вычислите корреляцию каждой строки `df` с последующей строкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0  18  38  47  76  14  96  58  74  13  86\n",
      "1  66   3  39  22  92  98   8  14  90  12\n",
      "2  84  31   3  68  11  98  51  15  21  59\n",
      "3  56  41  11  36  83  64  11  31  42  27\n",
      "4  87  60  83  55  14  53  49  56  92  27\n",
      "5  67  66  70   7  66  36  37  73  48  15\n",
      "6  89  40   6  21  75  37  29  33  42  98\n",
      "7  90  22  52   3  77  20  21   6  20  12\n",
      "Корреляция с последующей строкой:\n",
      "0   -0.3655\n",
      "1    0.1327\n",
      "2    0.2112\n",
      "3   -0.2950\n",
      "4    0.2972\n",
      "5   -0.0577\n",
      "6    0.4170\n",
      "7       NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример DataFrame\n",
    "df = pd.DataFrame(np.random.randint(1, 100, 80).reshape(8, -1))\n",
    "print(df)\n",
    "# Вычисление корреляции каждой строки с последующей\n",
    "correlation_with_next_row = df.corrwith(df.shift(-1, axis=0), axis=1)\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Корреляция с последующей строкой:\")\n",
    "print(correlation_with_next_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 65\n",
    "\n",
    "Замените все значения в обеих диагоналях `df` на 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0   0  71  36  19  64  89  73  90  86   0\n",
      "1  30   0  52  93  42  33  31  27   0  35\n",
      "2  45  39   0  70  59  42  83   0  13  31\n",
      "3  24  92  68   0   7  37   0  75  50  71\n",
      "4   1   8  30  64   0   0  56  45  87  34\n",
      "5  65  73  35  39   0   0  66  40  70  45\n",
      "6  74  80   8   0  60  33   0  39  13  17\n",
      "7  87  66   0  10  31  16   1   0  12  55\n",
      "8  81   0  15  67  14   5  34   1   0   9\n",
      "9   0  76  85   9  44  94  72  93  14   0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример DataFrame\n",
    "df = pd.DataFrame(np.random.randint(1, 100, 100).reshape(10, -1))\n",
    "\n",
    "# Замена значений в обеих диагоналях на 0\n",
    "for i in range(len(df)):\n",
    "    df.iloc[i, i] = 0\n",
    "    df.iloc[i, len(df) - i - 1] = 0\n",
    "\n",
    "# Вывод результата\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 66\n",
    "\n",
    "Из `df_grouped` получите в виде датафрейма группу, относящуюся к `apple`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     col1   col2  col3\n",
      "0   apple 0.7426    13\n",
      "1  banana 0.1159    14\n",
      "2  orange 0.6880    11\n",
      "3   apple 0.6958     4\n",
      "4  banana 0.2810    12\n",
      "5  orange 0.5159     8\n",
      "6   apple 0.4796    12\n",
      "7  banana 0.4524     7\n",
      "8  orange 0.7825     8\n",
      "    col1   col2  col3\n",
      "0  apple 0.7426    13\n",
      "3  apple 0.6958     4\n",
      "6  apple 0.4796    12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример DataFrame\n",
    "df = pd.DataFrame({'col1': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'col2': np.random.rand(9),\n",
    "                   'col3': np.random.randint(0, 15, 9)})\n",
    "print(df)\n",
    "# Группировка по 'col1'\n",
    "df_grouped = df.groupby(['col1'])\n",
    "\n",
    "# Получение группы 'apple'\n",
    "apple_group = df_grouped.get_group('apple')\n",
    "\n",
    "# Вывод результата\n",
    "print(apple_group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 67\n",
    "\n",
    "В `df` найдите второе по величине значение `taste` для `banana`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fruit  rating  price\n",
      "0   apple  0.9865     13\n",
      "1  banana  0.6467      4\n",
      "2  orange  0.6944      7\n",
      "3   apple  0.6017     14\n",
      "4  banana  0.6449      5\n",
      "5  orange  0.6218      7\n",
      "6   apple  0.7369      8\n",
      "7  banana  0.4053      6\n",
      "8  orange  0.0846      9\n",
      "0.644865045611628\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Пример DataFrame\n",
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})\n",
    "print(df)\n",
    "# Фильтрация данных для banana\n",
    "banana_data = df[df['fruit'] == 'banana']\n",
    "\n",
    "# Сортировка данных по убыванию значения 'rating'\n",
    "sorted_banana_data = banana_data.sort_values(by='rating', ascending=False)\n",
    "\n",
    "# Получение второго по величине значения 'rating'\n",
    "second_largest_taste = sorted_banana_data.iloc[1]['rating']\n",
    "\n",
    "# Вывод результата\n",
    "print(second_largest_taste)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 68\n",
    "\n",
    "В `df` вычислите среднюю цену `Price` каждого фрукта `Fruit`, сохраняя фрукт как еще один столбец вместо индекса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fruit  rating  price\n",
      "0   apple  0.4766      6\n",
      "1  banana  0.8153      8\n",
      "2  orange  0.0699      0\n",
      "3   apple  0.8201      2\n",
      "4  banana  0.0486     10\n",
      "5  orange  0.7455      6\n",
      "6   apple  0.2728     13\n",
      "7  banana  0.0747      6\n",
      "8  orange  0.7007      3\n",
      "    fruit  price\n",
      "0   apple 7.0000\n",
      "1  banana 8.0000\n",
      "2  orange 3.0000\n"
     ]
    }
   ],
   "source": [
    "# Пример DataFrame\n",
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})\n",
    "print(df)\n",
    "# Группировка по столбцу 'fruit' и вычисление среднего значения для 'price'\n",
    "result_df = df.groupby('fruit', as_index=False)['price'].mean()\n",
    "\n",
    "# Вывод результата\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 69\n",
    "\n",
    "Объединить датафреймы `df1` и `df2` по признакам `fruit-pazham` и `weight-kilo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fruit  weight  price\n",
      "0   apple    high      8\n",
      "1  banana  medium      0\n",
      "2  orange     low      9\n",
      "3   apple    high      2\n",
      "4  banana  medium     10\n",
      "5  orange     low      7\n",
      "6   apple    high      5\n",
      "7  banana  medium     13\n",
      "8  orange     low      1\n",
      "   pazham  kilo  price\n",
      "0   apple  high     14\n",
      "1  orange   low      8\n",
      "2    pine  high     12\n",
      "3   apple   low     14\n",
      "4  orange  high      3\n",
      "5    pine   low      9\n",
      "    fruit weight  price_x  price_y\n",
      "0   apple   high        8       14\n",
      "1   apple   high        2       14\n",
      "2   apple   high        5       14\n",
      "3  orange    low        9        8\n",
      "4  orange    low        7        8\n",
      "5  orange    low        1        8\n"
     ]
    }
   ],
   "source": [
    "# Примеры DataFrame\n",
    "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                    'weight': ['high', 'medium', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n",
    "                    'kilo': ['high', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 6)})\n",
    "print(df1)\n",
    "print(df2)\n",
    "# Объединение по признакам 'fruit-pazham' и 'weight-kilo'\n",
    "result_df = pd.merge(df1, df2, left_on=['fruit', 'weight'], right_on=['pazham', 'kilo'], how='inner')\n",
    "\n",
    "# Удаление лишних столбцов\n",
    "result_df = result_df.drop(['pazham', 'kilo'], axis=1)\n",
    "\n",
    "# Вывод результата\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 70\n",
    "\n",
    "Создайте в `df` два новых столбца, один из них — `lag1` (сдвиг столбца `a` вниз на 1 строку) столбца 'a', а другой — `lead1` (сдвиг столбца `b` вверх на 1 строку)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d  a_lag1  b_lead1\n",
      "0  47  72  75  21     NaN  94.0000\n",
      "1  93  94  79  70 47.0000  75.0000\n",
      "2  75  75  71  86 93.0000  69.0000\n",
      "3  36  69  87  25 75.0000  82.0000\n",
      "4  63  82  82  97 36.0000      NaN\n"
     ]
    }
   ],
   "source": [
    "# Пример DataFrame\n",
    "df = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns=list('abcd'))\n",
    "\n",
    "# Создание столбцов lag1 и lead1\n",
    "df['a_lag1'] = df['a'].shift(1)\n",
    "df['b_lead1'] = df['b'].shift(-1)\n",
    "\n",
    "# Вывод результата\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 71\n",
    "\n",
    "Получите частоты уникальных значений по всему датафрейму `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b  c  d\n",
      "0  3  1  1  2\n",
      "1  3  2  8  9\n",
      "2  2  1  9  1\n",
      "3  7  7  3  7\n",
      "4  7  1  1  3\n",
      "1    6\n",
      "3    4\n",
      "7    4\n",
      "2    3\n",
      "9    2\n",
      "8    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Пример DataFrame\n",
    "df = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns=list('abcd'))\n",
    "print(df)\n",
    "# Получение частот уникальных значений по всему датафрейму\n",
    "value_counts = df.stack().value_counts()\n",
    "\n",
    "# Вывод результата\n",
    "print(value_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение № 72\n",
    "\n",
    "Разделите столбец `row` в `df` так, чтобы сформировать датафрейм с 3 столбцами, как показано в примере выходных данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
